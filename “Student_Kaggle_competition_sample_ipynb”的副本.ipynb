{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ISpiw8kyz79N"
      },
      "source": [
        "# Convolutional Neural Networks\n",
        "\n",
        "## Project: Chest X-Ray Classification (Pneumonia vs Normal) \n",
        "\n",
        "---\n",
        "\n",
        "### Instructions\n",
        "For better understanding in this notebook some template code is already provided, and you will need to implement some additional functionalities to successfully complete this project.\n",
        "\n",
        "> **Note for Implementation:** Sections that have **'IMPLEMENTATION'** heading, indicates that the following block needs implementations. Instructions details are provided for each implementation block and `To-DO` statments are also provided in the code cell. Before Starting to implement the functionality please read the instrcutions carefully and Pleaase do not modify or remove the template code!\n",
        "\n",
        "---\n",
        "### Project Description \n",
        "\n",
        "In this notebook, you will be implememnting a Convolutional Neural Network (CNN) model. You will go through different stages of data pre-processing and you will explore different methods by which we can implement a CNN model. \n",
        "\n",
        "The notebook is divided into following parts:\n",
        "\n",
        "* Section 1: Import Dataset\n",
        "* Section 2: Data Analysis & Pre-processing\n",
        "* Section 3: Data Augumentation\n",
        "* Section 4: Develop a CNN to Classify Chest X-Ray (from Scratch)\n",
        "* Section 5: Develop a CNN to Classify Chest X-Ray (using Transfer Learning)\n",
        "* Section 6: Comparison of CNN Models\n",
        "* Section 7: Testing the best CNN Model\n",
        "\n",
        "---\n",
        "## Section 1: Import Dataset\n",
        "\n",
        "### Chest X-Ray Dataset\n",
        "\n",
        "For this project, we will be using [Chest X-Ray Images Dataset](https://www.kaggle.com/datasets/paultimothymooney/chest-xray-pneumonia). This dataset consists of `5,863` X-Ray images and provides two classes of images (Normal and Pneumonia).\n",
        "\n",
        "In the cells below, first we have imported the important libraries that will be useful throughout the notebook, we also have some constant variables like `DATASET_PATH, and IMG_CLASSES`. \n",
        "\n",
        "We also have a function `load_sample_imgs` which is used to load a sample training data, by which we can visualize the sample images for each class."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Dd5QwgvIoJjU",
        "outputId": "6dbd1734-2574-4f58-96f2-7cf187cdcbc1"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.chdir('/content/drive/MyDrive')"
      ],
      "metadata": {
        "id": "eEMnpUNkoQf9"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-03-12T19:33:33.331123Z",
          "iopub.status.busy": "2023-03-12T19:33:33.330506Z",
          "iopub.status.idle": "2023-03-12T19:33:33.487698Z",
          "shell.execute_reply": "2023-03-12T19:33:33.486676Z",
          "shell.execute_reply.started": "2023-03-12T19:33:33.331079Z"
        },
        "id": "NTdiz_Unz79P"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Downloaded Dataset Path (in google drive)\n",
        "DATASET_PATH = \"./chest_xray\"\n",
        "IMG_CLASSES = ['NORMAL', 'PNEUMONIA']\n",
        "\n",
        "def load_sample_imgs(path):\n",
        "    imgs = []\n",
        "    for cls in IMG_CLASSES:\n",
        "        dir_path = os.path.join(path, cls)\n",
        "        img_name = os.listdir(dir_path)[0]\n",
        "        img = cv2.imread(os.path.join(dir_path, img_name))\n",
        "        cls_index = IMG_CLASSES.index(cls)\n",
        "        imgs.append([img, cls_index])\n",
        "    \n",
        "    return imgs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-03-12T19:33:33.490082Z",
          "iopub.status.busy": "2023-03-12T19:33:33.489671Z",
          "iopub.status.idle": "2023-03-12T19:33:34.162870Z",
          "shell.execute_reply": "2023-03-12T19:33:34.161778Z",
          "shell.execute_reply.started": "2023-03-12T19:33:33.490042Z"
        },
        "id": "BDR6jdZdz79P",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 365
        },
        "outputId": "9cc3b655-f7d4-46c4-fcf2-31e3aff69897"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-4-d36388b0b231>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0msample_imgs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_sample_imgs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDATASET_PATH\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'train'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0max\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msubplots\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mncols\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfigsize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m8\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msuptitle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Sample Training Images of Chest X-Ray'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfontsize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m16\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.95\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-3-7146c1fadd0c>\u001b[0m in \u001b[0;36mload_sample_imgs\u001b[0;34m(path)\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mcls\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mIMG_CLASSES\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0mdir_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m         \u001b[0mimg_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdir_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m         \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdir_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimg_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m         \u001b[0mcls_index\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mIMG_CLASSES\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcls\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: './chest_xray/train/NORMAL'"
          ]
        }
      ],
      "source": [
        "sample_imgs = load_sample_imgs(os.path.join(DATASET_PATH, 'train'))\n",
        "fig, ax = plt.subplots(ncols=2, figsize=(8, 4))\n",
        "\n",
        "plt.suptitle('Sample Training Images of Chest X-Ray', fontsize=16, y=0.95)\n",
        "\n",
        "for index in range(2):\n",
        "    img, cls_index = sample_imgs[index]\n",
        "    ax[index].imshow(img)\n",
        "    ax[index].set_xticks([])             \n",
        "    ax[index].set_yticks([])\n",
        "    ax[index].set_xlabel(IMG_CLASSES[cls_index])\n",
        "    ax[index].spines['top'].set_visible(False)\n",
        "    ax[index].spines['right'].set_visible(False)        \n",
        "    ax[index].spines['left'].set_visible(False)                \n",
        "    ax[index].spines['bottom'].set_visible(False)                \n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TQ402Os-z79Q"
      },
      "source": [
        "In the figure above, we can see the visualization of sample training images for each class.\n",
        "\n",
        "> **Note:** While loading the sample image data, we have loaded the data in format [image, cls_index]. This is one of the many approaches by which we can load the complete dataset in a structured manner.\n",
        "\n",
        "### IMPLEMENTATION\n",
        "\n",
        "While visualizing the sample images, we can see that both images are not of same size, it means in the dataset all the images are of not same size. In the cell below you can see a constant variable **IMG_SIZE**, this varaible will be used throughout the notebook and will represent the size of images in the dataset. **Do a research and choose an appropriate Image Size for the images.**\n",
        "\n",
        "Now we will load the whole dataset. We know that the dataset is divided into three different subsets: `Training, Validation and Testing`. **So in the code cell below you will need to complete the implementation of the function which will be used to load the dataset for given path, and while loading the dataset resize the images according to the Image size that you have selected**. \n",
        "\n",
        "> **Note:** Use the same data loading structure that have been used while loading the sample data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-03-12T19:34:12.451268Z",
          "iopub.status.busy": "2023-03-12T19:34:12.450158Z",
          "iopub.status.idle": "2023-03-12T19:34:12.460332Z",
          "shell.execute_reply": "2023-03-12T19:34:12.459412Z",
          "shell.execute_reply.started": "2023-03-12T19:34:12.451221Z"
        },
        "id": "3wwmJ_yJz79Q"
      },
      "outputs": [],
      "source": [
        "#IMG_SIZE represents height and width of an image\n",
        "#TODO: Choose an appropriate Image Size, example: IMG_SIZE = 32, IMG_SIZE = 64, etc.\n",
        "IMG_SIZE = None\n",
        "\n",
        "def load_data(path):\n",
        "    data = []    \n",
        "    # TODO: Implement the functionality to load the dataset for given data path.\n",
        "    \n",
        "    return data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VGIhNbYOz79Q"
      },
      "source": [
        "Now after developing the data loading function, we will read the `Training` and `Validation` datasets. For now we will not going to load the `Testing` dataset because it will be used in the end to test the CNN models."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-03-12T19:34:14.068108Z",
          "iopub.status.busy": "2023-03-12T19:34:14.067154Z",
          "iopub.status.idle": "2023-03-12T19:35:43.848521Z",
          "shell.execute_reply": "2023-03-12T19:35:43.847403Z",
          "shell.execute_reply.started": "2023-03-12T19:34:14.068053Z"
        },
        "id": "AoHczjHEz79R"
      },
      "outputs": [],
      "source": [
        "train_data = load_data(os.path.join(DATASET_PATH, 'train'))\n",
        "valid_data = load_data(os.path.join(DATASET_PATH, 'val'))\n",
        "\n",
        "# print number of images in each dataset\n",
        "print(f'There are {len(train_data)} Training Images.')\n",
        "print(f'There are {len(valid_data)} Validation Images.')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E7a2fbRsz79R"
      },
      "source": [
        "We can see that we don't have a good amount of data for validation set, so now we need to combine both datasets, then split into training and testing sets. \n",
        "\n",
        "\n",
        "### IMPLEMENTATION\n",
        "**In the cell below, first combine both sets, then split into training and validation sets. (80% for Training, 20% for Validation)**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-03-12T19:35:43.851193Z",
          "iopub.status.busy": "2023-03-12T19:35:43.850770Z",
          "iopub.status.idle": "2023-03-12T19:35:44.181799Z",
          "shell.execute_reply": "2023-03-12T19:35:44.180661Z",
          "shell.execute_reply.started": "2023-03-12T19:35:43.851121Z"
        },
        "id": "7-svW_Prz79R"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "#TODO: Combine the training and validation sets \n",
        "\n",
        "#TODO: Split the dataset, 80% for training and 20% for testing\n",
        "\n",
        "# print number of images in each dataset\n",
        "print(f'There are {len(train_data)} Training Images.')\n",
        "print(f'There are {len(valid_data)} Validation Images.')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QwghpLDHz79R"
      },
      "source": [
        "---\n",
        "## Section 2: Data Pre-processing\n",
        "\n",
        "Before starting to train the Deep Learning model we need to setup the dataset for best possible results. In our case as we are working with images the first thing to note is the size of all the images in the dataset and then we can move forward with all other techniques.\n",
        "\n",
        "In our case as we have already setup the constant value for the size of all the images in the dataset so we don't need to worry about the size of the images in the dataset. Now we have multiple other steps that we need to take, first we will going to split the features and labels from the dataset that we have prepared early.\n",
        "\n",
        "### Implementation\n",
        "In the function below provide the code to split the features and labels into their seperate lists and then return the numpy arrays for each one of them."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-03-12T19:35:44.184085Z",
          "iopub.status.busy": "2023-03-12T19:35:44.183616Z",
          "iopub.status.idle": "2023-03-12T19:35:44.191549Z",
          "shell.execute_reply": "2023-03-12T19:35:44.190254Z",
          "shell.execute_reply.started": "2023-03-12T19:35:44.184045Z"
        },
        "id": "dXJbErI-z79R"
      },
      "outputs": [],
      "source": [
        "def split_features_labels(data):\n",
        "    # TODO: Split features and Labels and return numpy array for feature and labels\n",
        "    \n",
        "    return None, None"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WdrbPRfJz79R"
      },
      "source": [
        "Now as the function is ready to be used, so we will going to use the function to split features and labels from the dataset. First we will going to call the function for training dataset and then for validation dataset."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-03-12T19:35:44.195518Z",
          "iopub.status.busy": "2023-03-12T19:35:44.195025Z",
          "iopub.status.idle": "2023-03-12T19:35:44.435490Z",
          "shell.execute_reply": "2023-03-12T19:35:44.434440Z",
          "shell.execute_reply.started": "2023-03-12T19:35:44.195481Z"
        },
        "id": "nLnvCyB9z79S"
      },
      "outputs": [],
      "source": [
        "x_train, y_train = split_features_labels(train_data)\n",
        "x_valid, y_valid = split_features_labels(valid_data)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TzO4tptIz79S"
      },
      "source": [
        "When using TensorFlow as backend, Keras CNNs require a 4D array (which we'll also refer to as a 4D tensor) as input, with shape\n",
        "\n",
        "$$\n",
        "(\\text{number_of_samples}, \\text{image_height}, \\text{image_width}, \\text{channels}),\n",
        "$$\n",
        "\n",
        "where `number_of_samples` corresponds to the total number of images (or samples), and `image_height`, `image_width`, and `channels` correspond to the each image height, width, and channels.\n",
        "\n",
        "By the running the cell below, we can check the tensor size of our training and validation data. First we will going to check the size of features and then we will move with labels/classes. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-03-12T19:35:44.437679Z",
          "iopub.status.busy": "2023-03-12T19:35:44.437269Z",
          "iopub.status.idle": "2023-03-12T19:35:44.445044Z",
          "shell.execute_reply": "2023-03-12T19:35:44.443772Z",
          "shell.execute_reply.started": "2023-03-12T19:35:44.437639Z"
        },
        "id": "gDMa6Yxoz79S"
      },
      "outputs": [],
      "source": [
        "print(f'Training Features Tensor Shape: {x_train.shape}')\n",
        "print(f'Validation Features Tensor Shape: {x_valid.shape}')\n",
        "print('\\n')\n",
        "print(f'Training Labels Tensor Shape: {y_train.shape}')\n",
        "print(f'Validation Labels Tensor Shape: {y_valid.shape}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D7jNlnoRz79S"
      },
      "source": [
        "### IMPLEMENTATION\n",
        "For training and validation labels, we can see that we have tensors of shape `(200,)` and `(16,)`, which means we have a 1-D tensor. This is a binary dataset, which means we just have 2 classes in the dataset. For the better performance of the model we can use `One-Hot-Encoding` technique to One Hot Encode the labels, this is not a necessary step while working with Binary Classification data, but this is a cruicial step for Multi-Class Classification and that is why we also need to learn this step.\n",
        "\n",
        "In the cell below you can implement the functionality to One-Hot Encode the labels of the dataset."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-03-12T19:35:44.447627Z",
          "iopub.status.busy": "2023-03-12T19:35:44.446729Z",
          "iopub.status.idle": "2023-03-12T19:35:51.129128Z",
          "shell.execute_reply": "2023-03-12T19:35:51.128038Z",
          "shell.execute_reply.started": "2023-03-12T19:35:44.447589Z"
        },
        "id": "-FMN8aNhz79S"
      },
      "outputs": [],
      "source": [
        "from keras.utils import to_categorical\n",
        "\n",
        "#TODO: Implement One HOT ENCODING for training and validation labels"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KuvbTvJKz79S"
      },
      "source": [
        "Now after implementing the `One-Hot Encoding` functionality we can again check the shape of the labels."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-03-12T19:35:51.134405Z",
          "iopub.status.busy": "2023-03-12T19:35:51.132589Z",
          "iopub.status.idle": "2023-03-12T19:35:51.140581Z",
          "shell.execute_reply": "2023-03-12T19:35:51.139433Z",
          "shell.execute_reply.started": "2023-03-12T19:35:51.134358Z"
        },
        "id": "1UgJmfoSz79S"
      },
      "outputs": [],
      "source": [
        "print(f'Training Labels Tensor Shape: {y_train.shape}')\n",
        "print(f'Validation Labels Tensor Shape: {y_valid.shape}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TFmCLNVtz79S"
      },
      "source": [
        "Now we have setup the features and labels of the dataset, let's explore the data a bit more and let us visualize the channels of the images. We know that the data is in `3 Channels` which means that the images in the dataset are having `Reg, Blue and Green` color channel which is also known as `RGB`. By running the cell below, we can visualize the image in each color channel. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-03-12T19:35:51.143008Z",
          "iopub.status.busy": "2023-03-12T19:35:51.142429Z",
          "iopub.status.idle": "2023-03-12T19:35:51.931527Z",
          "shell.execute_reply": "2023-03-12T19:35:51.930550Z",
          "shell.execute_reply.started": "2023-03-12T19:35:51.142970Z"
        },
        "id": "BkK_AC07z79T"
      },
      "outputs": [],
      "source": [
        "image = x_train[0]\n",
        "\n",
        "# plotting the original image and the RGB channels\n",
        "f, (ax1, ax2, ax3, ax4) = plt.subplots(1, 4, sharey=True)\n",
        "f.set_figwidth(15)\n",
        "ax1.imshow(image)\n",
        "\n",
        "# RGB channels\n",
        "# CHANNELID : 0 for Red, 1 for Green, 2 for Blue. \n",
        "ax2.imshow(image[:, : , 0]) #Red\n",
        "ax3.imshow(image[:, : , 1]) #Green\n",
        "ax4.imshow(image[:, : , 2]) #Blue\n",
        "f.suptitle('Different Channels of Chest X-Ray Image')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jm-WCqPUz79T"
      },
      "source": [
        "---\n",
        "## Section 3: Data Augumentation\n",
        "\n",
        "Data augmentation is a technique used in machine learning to artificially increase the size and diversity of a dataset by generating new data from existing data. Data augmentation provides improvement in the performance of machine learning models by exposing them to a wider range of variations in the data. Data augmentation is commonly used in computer vision applications such as image classification, object detection, and segmentation. \n",
        "\n",
        "For data augumentation we can make use of multiple techniques like Flipping, Rotation, Scaling, Cropping, Translation, Adding Noise to the image, etc. \n",
        "\n",
        "### IMPLEMENTATION\n",
        "For Data Augumentation we will be using `ImageDataGenerator` function provided by `keras` library. In the cell below you have boilerplate code for the initialization of ImageDataGenerator object, while initializing the object, we need to pass in arguments which Augumentation techniques we need to use. \n",
        "\n",
        "**In the code below, we already have two arguments (Augumentation Techniques), you need to provide at least 2 more arguments to Augument the data, you can provide more as you want.** "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-03-12T19:35:51.934680Z",
          "iopub.status.busy": "2023-03-12T19:35:51.933050Z",
          "iopub.status.idle": "2023-03-12T19:35:51.950019Z",
          "shell.execute_reply": "2023-03-12T19:35:51.948906Z",
          "shell.execute_reply.started": "2023-03-12T19:35:51.934637Z"
        },
        "id": "MhR-avWmz79T"
      },
      "outputs": [],
      "source": [
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "# TODO: Provide at least 2 more data augumentation parameters,\n",
        "# we need to apply at least 4 different augumentation techniques.\n",
        "datagen = ImageDataGenerator(rotation_range=40, width_shift_range=0.2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8IyiSlXBz79T"
      },
      "source": [
        "Now after initializing the data augumentation object, we need to use this object to visualize the dataset. \n",
        "\n",
        "In the cell below, we will use one single sample image and generate the augumented images. The generator object will augument the sample image and generate different samples of the images by the help of the techniques which we have provided. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-03-12T19:35:51.953544Z",
          "iopub.status.busy": "2023-03-12T19:35:51.953200Z",
          "iopub.status.idle": "2023-03-12T19:35:54.473173Z",
          "shell.execute_reply": "2023-03-12T19:35:54.472248Z",
          "shell.execute_reply.started": "2023-03-12T19:35:51.953515Z"
        },
        "id": "tOeDHhrwz79T"
      },
      "outputs": [],
      "source": [
        "fig, axes = plt.subplots(4, 4, figsize=(15, 15))\n",
        "\n",
        "temp_batch = datagen.flow(x_train[:1], batch_size=1)\n",
        "\n",
        "index = 0\n",
        "for i in range(4):\n",
        "    for j in range(4):\n",
        "        img = next(temp_batch)[0]\n",
        "        axes[i, j].imshow(img[:,:,0])\n",
        "        index = index +1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0J1I3vLXz79T"
      },
      "source": [
        "---\n",
        "## Section 4: Develop a CNN to Classify Chest X-Ray (from Scratch)\n",
        "\n",
        "We have completed the Data pre-processing part, now it is the time to start developing the Convolutional Neural Network model. For this project we will be going to work with keras and Tensorflow library to develop and train the CNN model. CNN models have multiple layers that we can use, some of the standard layers that we need to use while working with CNN models are `Convolutinal Layer, Pooling Layer, Dropout Layer, Flatten Layer and Dense Layer`.\n",
        "\n",
        "### IMPLEMENTATION\n",
        "Now in the cell below we will going to define our model architecture. You have been given a boiler plate code with 1 Convolutional Layer and Output Layer of the model. \n",
        "\n",
        "**By using the boilerplate code develop a Convolutional Model architecutre. You need to use Conv2D, Pooling, Dropout and Dense Layers, etc. Please don't change anything in the boilerplate code.**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-03-12T19:36:18.469883Z",
          "iopub.status.busy": "2023-03-12T19:36:18.469470Z",
          "iopub.status.idle": "2023-03-12T19:36:18.634970Z",
          "shell.execute_reply": "2023-03-12T19:36:18.634125Z",
          "shell.execute_reply.started": "2023-03-12T19:36:18.469846Z"
        },
        "id": "ItyQZX1hz79T"
      },
      "outputs": [],
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Conv2D, MaxPooling2D, Dropout, Flatten\n",
        "\n",
        "# Building CNN model\n",
        "# Initializing the Model\n",
        "cnn_model = Sequential()\n",
        "\n",
        "# Depth of Conv Layer(filters) will increase with each conv2D layer and by the help of pooling layer \n",
        "# the dimensionality will decrease and also it will prevent overfitting.\n",
        "# Conv Layer\n",
        "cnn_model.add(Conv2D(filters=32, kernel_size=3, padding=\"same\", activation=\"relu\",\\\n",
        "                     input_shape=(IMG_SIZE, IMG_SIZE, 3)))\n",
        "# Pooling layer\n",
        "cnn_model.add(MaxPooling2D(pool_size=2))\n",
        "\n",
        "\n",
        "# TODO: Develop a CNN Model architecutre, in this section add Conv, Pooling and Dropout layers.\n",
        "\n",
        "# Hint: Consider adding a pooling layer before flattening the CNN outputs so that number of params in dense layer is not too much.\n",
        "# Now adding a Flatten layer to flatten the matrix into a vector so then we can classify the data\n",
        "cnn_model.add(Flatten())\n",
        "\n",
        "# TODO: In this provide some Dense Layers before the output layer.\n",
        "# Hint: Do not use too many units in dense layer (you may find that colab's memory limit reaches if you use too many params)\n",
        "\n",
        "# Output Layer of the Model\n",
        "cnn_model.add(Dense(2, activation=\"softmax\"))\n",
        "\n",
        "# Model Summary\n",
        "cnn_model.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ikN1WvBoz79U"
      },
      "source": [
        "The output of the above cell shows the summary of the CNN model. With the help of the model summary, we can see the trainable parameters, the complexity of the model, we can also check the output data shape for each layer. This is a good way to check the complexity of the model. \n",
        "\n",
        "Now we need to compile the model. While compiling the model we need to provide `loss function`, `optimizer`, and `metrics` which will be used during the training process of the Deep Learning model. There are many different choices of loss functions and optimizers which are avilable and we need to choose the best for our use case. \n",
        "\n",
        "### IMPLEMENTATION\n",
        "In the cell below, **you need to provide the LOSS function and Optimization Function for the CNN Model**.\n",
        "\n",
        "- [Available Loss Functions](https://keras.io/api/losses/probabilistic_losses/)\n",
        "- [Available Optimization Functions](https://keras.io/api/optimizers/)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-03-12T19:36:21.343901Z",
          "iopub.status.busy": "2023-03-12T19:36:21.343506Z",
          "iopub.status.idle": "2023-03-12T19:36:21.362259Z",
          "shell.execute_reply": "2023-03-12T19:36:21.361297Z",
          "shell.execute_reply.started": "2023-03-12T19:36:21.343865Z"
        },
        "id": "1XmkJEo1z79U"
      },
      "outputs": [],
      "source": [
        "#TODO: Provide Loss and Optimizer functions\n",
        "cnn_model.compile(loss=None, optimizer=None, metrics=[\"accuracy\"])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F6XzuxQ5z79U"
      },
      "source": [
        "### IMPLEMENTATION\n",
        "\n",
        "Now in the cell below we will be going to train our Convolutional Neural Network Model. For the training of the CNN model, **you need to provide a `Batch size` and `Number of Epochs`**. And after that you can run this cell to start the training process of the model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-03-12T19:50:18.990017Z",
          "iopub.status.busy": "2023-03-12T19:50:18.989062Z",
          "iopub.status.idle": "2023-03-12T19:58:29.792311Z",
          "shell.execute_reply": "2023-03-12T19:58:29.791162Z",
          "shell.execute_reply.started": "2023-03-12T19:50:18.989963Z"
        },
        "id": "gWlbJaAyz79U"
      },
      "outputs": [],
      "source": [
        "#TODO: You need to provide the Number of Epochs and Batch Size\n",
        "Epochs = None\n",
        "BATCH_SIZE = None\n",
        "\n",
        "cnn_model_history = cnn_model.fit(datagen.flow(x_train, y_train, batch_size=BATCH_SIZE),\\\n",
        "                                validation_data=(x_valid, y_valid), epochs=Epochs,\\\n",
        "                                verbose=1, shuffle=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y4EW4pK-z79U"
      },
      "source": [
        "#### Evaluating the Trained Model\n",
        "After training the Model, it is a good paractice to evaluate the model on Training Dataset to get the final Training Accuracy and Loss of the Model. By running the cell below you will be able to find out the training accuracy and loss of the CNN model. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-03-12T19:58:29.794926Z",
          "iopub.status.busy": "2023-03-12T19:58:29.794470Z",
          "iopub.status.idle": "2023-03-12T19:58:32.581567Z",
          "shell.execute_reply": "2023-03-12T19:58:32.580428Z",
          "shell.execute_reply.started": "2023-03-12T19:58:29.794893Z"
        },
        "id": "Yzi3pklfz79U"
      },
      "outputs": [],
      "source": [
        "training_score = cnn_model.evaluate(x_train, y_train)\n",
        "\n",
        "print(\"\\nTraining Accuracy:\", round((training_score[1] * 100), 3),\"%\")\n",
        "print(\"Training Loss:\", training_score[0])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RcCodkepz79U"
      },
      "source": [
        "---\n",
        "## Section 5: Develop a CNN to Classify Chest X-Ray (using Transfer Learning)\n",
        "\n",
        "Now in this section we will be using pre-trained CNN model and train it using Transfer Learning Techniques. Transfer learning is a powerfull technique by which we can make use of complex and large pre-trained models and improve those models on our datasets. We have many different pre-trained CNN models available, you can access the list of all pre-trainned models in Keras Document, [link to pre-trained models](https://keras.io/api/applications/). \n",
        "\n",
        "There are different types of Transfer Learning techniques available, for this project we will be using `Fine Tuning` approach. Fine-tuning in transfer learning is a technique which is used to adapt a pre-trained model to a new dataset. This involves taking a pre-trained model that has been trained on a large dataset, and then improving it for a different dataset. The idea is that the model has already learned some general features and patterns from the original dataset, and these can be useful for the new dataset.\n",
        "\n",
        "### IMPLEMENTATION\n",
        "\n",
        "The First step to implement the Fine Tuning approach is to initialize a pre-trained model. **From the list of all available pre-trained models, choose a model according to your choice and initialize it in the cell given below**."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-03-12T19:35:54.475141Z",
          "iopub.status.busy": "2023-03-12T19:35:54.474547Z",
          "iopub.status.idle": "2023-03-12T19:35:58.815564Z",
          "shell.execute_reply": "2023-03-12T19:35:58.814535Z",
          "shell.execute_reply.started": "2023-03-12T19:35:54.475103Z"
        },
        "id": "LsAwV09Bz79U"
      },
      "outputs": [],
      "source": [
        "# TODO: Initialize a pre-trained model\n",
        "pretrained_model = None\n",
        "\n",
        "# We don't need to train the pre-trained model we just need to fine-tune it\n",
        "for layer in pretrained_model.layers:\n",
        "        layer.trainable=False\n",
        "# Note that setting layer.trainable = True will train model from scratch. \n",
        "# In this case, only the architechure will be the same as your pretrained models"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gv12OvDnz79U"
      },
      "source": [
        "Now in the second step of Fine Tuning, we need to add some `Dense` layers to the model. As you can see in the cell above, we have explicitly turned off the training of all the layers inside the pre-trainned model because we don't want the pre-trained model to be trained we just want to add some layers at the end of the model and then we will going to train those layers.\n",
        "\n",
        "### IMPLEMENTATION\n",
        "In the cell below, you have given a boilerplate code, the loaded pre-trained model has been attached to the CNN architecture and also the output layer of the model is initialized. **You need to add some more Dense, Dropout Layers in the CNN model architecture**."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-03-12T19:36:25.237683Z",
          "iopub.status.busy": "2023-03-12T19:36:25.236650Z",
          "iopub.status.idle": "2023-03-12T19:36:25.696108Z",
          "shell.execute_reply": "2023-03-12T19:36:25.695058Z",
          "shell.execute_reply.started": "2023-03-12T19:36:25.237646Z"
        },
        "id": "WR8fXsR9z79U"
      },
      "outputs": [],
      "source": [
        "transfer_model = Sequential()     \n",
        "transfer_model.add(pretrained_model)\n",
        "transfer_model.add(Flatten())\n",
        "# Hint: Add a pooling layer to reduce the input size to dense layer.\n",
        "\n",
        "#TODO: Add some Dense, Dropout Layers\n",
        "\n",
        "# Hint: Keep your size of Dense layer small (i.e. number of units in the dense layers. You may find colab crashing if you have too many params.)\n",
        "# Output Layer of the Model\n",
        "transfer_model.add(Dense(2, activation='softmax'))\n",
        "transfer_model.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_1ofroJ3z79V"
      },
      "source": [
        "In the Model Summary we can see that, the total number of parameters are much more higher than the trainable parameters. This is the best part of fine-tuning a CNN model, because we will use a pre-trained model and adapt it on our dataset even if we have less resources to train a large complex model.\n",
        "\n",
        "Now we need to compile the model. While compiling the model we need to provide `loss function`, `optimizer`, and `metrics` which will be used during the training process of the Deep Learning model. There are many different choices of loss functions and optimizers which are avilable and we need to choose the best for our use case. \n",
        "\n",
        "### IMPLEMENTATION\n",
        "In the cell below, **you need to provide the LOSS function and Optimization Function for the CNN Model**.\n",
        "\n",
        "- [Available Loss Functions](https://keras.io/api/losses/probabilistic_losses/)\n",
        "- [Available Optimization Functions](https://keras.io/api/optimizers/)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-03-12T19:36:54.334230Z",
          "iopub.status.busy": "2023-03-12T19:36:54.333277Z",
          "iopub.status.idle": "2023-03-12T19:36:54.349966Z",
          "shell.execute_reply": "2023-03-12T19:36:54.348751Z",
          "shell.execute_reply.started": "2023-03-12T19:36:54.334172Z"
        },
        "id": "n02YLRG1z79V"
      },
      "outputs": [],
      "source": [
        "#TODO: Provide Loss and Optimizer functions\n",
        "transfer_model.compile(optimizer=None, loss=None, metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wedvh5wtz79V"
      },
      "source": [
        "### IMPLEMENTATION\n",
        "\n",
        "Now in the cell below we will be going to train the Convolutional Neural Network Model. As we have trained the CNN model previously, it will going to be the same steps. **Provide the code for training the CNN Model, and train the model on same number of Epochs as the previous CNN model**."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-03-12T19:37:37.053839Z",
          "iopub.status.busy": "2023-03-12T19:37:37.053422Z",
          "iopub.status.idle": "2023-03-12T19:46:59.757797Z",
          "shell.execute_reply": "2023-03-12T19:46:59.756745Z",
          "shell.execute_reply.started": "2023-03-12T19:37:37.053797Z"
        },
        "id": "4x-Ph79Qz79V"
      },
      "outputs": [],
      "source": [
        "#TODO: You need to provide the Batch Size, Number of Epochs will be the same as before\n",
        "BATCH_SIZE = None\n",
        "\n",
        "transfer_model_history = transfer_model.fit(datagen.flow(x_train, y_train, batch_size=BATCH_SIZE),\\\n",
        "                                            validation_data=(x_valid, y_valid), epochs=Epochs,\\\n",
        "                                            verbose=1, shuffle=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CcE9MWcJz79V"
      },
      "source": [
        "#### Evaluating the Trained Model\n",
        "After training the Model, it is a good paractice to evaluate the model on Training Dataset to get the final Training Accuracy and Loss of the Model. By running the cell below you will be able to find out the training accuracy and loss of the CNN model which is trained by transfer learning. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-03-12T19:47:17.523482Z",
          "iopub.status.busy": "2023-03-12T19:47:17.522833Z",
          "iopub.status.idle": "2023-03-12T19:47:23.903313Z",
          "shell.execute_reply": "2023-03-12T19:47:23.901886Z",
          "shell.execute_reply.started": "2023-03-12T19:47:17.523432Z"
        },
        "id": "nhc32hQ1z79V"
      },
      "outputs": [],
      "source": [
        "transfer_model_score = transfer_model.evaluate(x_train, y_train)\n",
        "\n",
        "print(\"\\nTraining Accuracy:\", round((transfer_model_score[1] * 100), 3),\"%\")\n",
        "print(\"Training Loss:\", transfer_model_score[0])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9LUPfsasz79V"
      },
      "source": [
        "---\n",
        "## Section 6: Comparison of CNN Models\n",
        "\n",
        "### Visualizing Model Loss And Accuracy\n",
        "\n",
        "We have successfully trained both CNN models and now it's time to compare the accuracy and loss of both models to know which one is the best one. While training the models, we can see that we have used **cnn_model_history variable** and **transfer_model_history variable**, these variable are used to store the accuracy and loss of the model for all Epochs. These variable holds the data in the form of python dictionary.\n",
        "\n",
        "### IMPLEMENTATION\n",
        "**By using the `cnn_model_history` and `transfer_model_history` variables and matplotlib library plot the Accuracy and Loss graphs of the models. You need to plot Accuracy and Loss graphs having Training and Validation data for both models.**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-03-12T20:00:32.890573Z",
          "iopub.status.busy": "2023-03-12T20:00:32.889444Z",
          "iopub.status.idle": "2023-03-12T20:00:33.183055Z",
          "shell.execute_reply": "2023-03-12T20:00:33.182012Z",
          "shell.execute_reply.started": "2023-03-12T20:00:32.890527Z"
        },
        "id": "C9Th_gBAz79V"
      },
      "outputs": [],
      "source": [
        "#TODO: Plot the Accuracy Graph"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-03-12T20:01:36.168718Z",
          "iopub.status.busy": "2023-03-12T20:01:36.168296Z",
          "iopub.status.idle": "2023-03-12T20:01:36.436584Z",
          "shell.execute_reply": "2023-03-12T20:01:36.435389Z",
          "shell.execute_reply.started": "2023-03-12T20:01:36.168666Z"
        },
        "id": "Oz19ZBmIz79V"
      },
      "outputs": [],
      "source": [
        "#TODO: Plot the Loss Graph"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BoUmQgffz79V"
      },
      "source": [
        "---\n",
        "## Section 7: Testing the best CNN Model\n",
        "\n",
        "Now in this last section of the Notebook, we will test the best CNN model.\n",
        "\n",
        "#### IMPLEMENTATION\n",
        "**Load the testing set in the cell below.**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-03-12T20:03:13.268522Z",
          "iopub.status.busy": "2023-03-12T20:03:13.268117Z",
          "iopub.status.idle": "2023-03-12T20:03:22.958488Z",
          "shell.execute_reply": "2023-03-12T20:03:22.957392Z",
          "shell.execute_reply.started": "2023-03-12T20:03:13.268486Z"
        },
        "id": "dGNesuEbz79W"
      },
      "outputs": [],
      "source": [
        "# TODO: Load the Testing Dataset\n",
        "test_data = None\n",
        "\n",
        "# print number of images in testing dataset\n",
        "print(f'There are {len(test_data)} Testing Images.')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7hufQ9ZAz79W"
      },
      "source": [
        "### IMPLEMENTATION\n",
        "**Split the Features and Labels of the Testing Set.**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-03-12T20:03:22.960885Z",
          "iopub.status.busy": "2023-03-12T20:03:22.960391Z",
          "iopub.status.idle": "2023-03-12T20:03:23.001588Z",
          "shell.execute_reply": "2023-03-12T20:03:23.000223Z",
          "shell.execute_reply.started": "2023-03-12T20:03:22.960835Z"
        },
        "id": "cZodIEyFz79W"
      },
      "outputs": [],
      "source": [
        "# TODO: Split the Features and Labels of Testing Data\n",
        "x_test, y_test = None\n",
        "\n",
        "print(f'Testing Features Tensor Shape: {x_test.shape}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Uxnoym3Hz79W"
      },
      "source": [
        "We have loaded and setup the testing dataset, now it's time to use the best model and make the prediction for testing images."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-03-12T20:03:31.130390Z",
          "iopub.status.busy": "2023-03-12T20:03:31.129664Z",
          "iopub.status.idle": "2023-03-12T20:03:32.998447Z",
          "shell.execute_reply": "2023-03-12T20:03:32.997322Z",
          "shell.execute_reply.started": "2023-03-12T20:03:31.130351Z"
        },
        "id": "Zmy7jG5yz79W"
      },
      "outputs": [],
      "source": [
        "predictions = transfer_model.predict(x_test)\n",
        "prediction_labels = np.argmax(predictions, axis=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YHUI-1YIz79W"
      },
      "source": [
        "### Confusion Matrix\n",
        "A confusion matrix is a table used to evaluate the performance of a classification model. It shows the number of correct and incorrect predictions made by the model compared to the actual outcomes. The matrix is usually presented as a square table, with the rows representing the actual class labels and the columns representing the predicted class labels. The confusion matrix provides several useful metrics for evaluating the performance of a classification model, such as accuracy, precision, recall, and F1 score. \n",
        "\n",
        "### IMPLEMENTATION\n",
        "We have original labels and predicted labels, now you need to use **scikit-learn** and **matplotlib** lilbrary to plot the confusion matrix."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-03-12T20:03:36.736614Z",
          "iopub.status.busy": "2023-03-12T20:03:36.735574Z",
          "iopub.status.idle": "2023-03-12T20:03:37.346568Z",
          "shell.execute_reply": "2023-03-12T20:03:37.344378Z",
          "shell.execute_reply.started": "2023-03-12T20:03:36.736575Z"
        },
        "id": "bGv14SRTz79W"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import ConfusionMatrixDisplay, classification_report\n",
        "\n",
        "#TODO: Compute and Plot the Confusion matrix for testing data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tTlBUYxGz79W"
      },
      "source": [
        "### Classification Report\n",
        "\n",
        "A classification report is a summary of the key performance metrics for a classification model. The classification report includes several important metrics, including precision, recall, F1 score, and support. These metrics provide information about the model's ability to correctly identify positive and negative instances, as well as the balance between precision and recall.\n",
        "\n",
        "Please run the cell below to generate the classification report for the Best Performing CNN Model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-03-12T20:03:41.459189Z",
          "iopub.status.busy": "2023-03-12T20:03:41.458154Z",
          "iopub.status.idle": "2023-03-12T20:03:41.471691Z",
          "shell.execute_reply": "2023-03-12T20:03:41.470448Z",
          "shell.execute_reply.started": "2023-03-12T20:03:41.459137Z"
        },
        "id": "vAc2KcBJz79W"
      },
      "outputs": [],
      "source": [
        "print(classification_report(y_test, prediction_labels))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wLXvp6agz79W"
      },
      "source": [
        "---\n",
        "## Conclusion\n",
        "\n",
        "In the Notebook, we have learned how we can develop Convolutional Neural Network Models. We have learned how we can develop our own CNN architectures and how we can make use of Transfer Learning Techniques. We have gone through the data preperation part, model development part and finally we have evaluated and tested the CNN Models. "
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.14"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}