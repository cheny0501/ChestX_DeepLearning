{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ISpiw8kyz79N"
      },
      "source": [
        "# Convolutional Neural Networks\n",
        "\n",
        "## Project: Chest X-Ray Classification (Pneumonia vs Normal) \n",
        "\n",
        "---\n",
        "\n",
        "### Instructions\n",
        "For better understanding in this notebook some template code is already provided, and you will need to implement some additional functionalities to successfully complete this project.\n",
        "\n",
        "> **Note for Implementation:** Sections that have **'IMPLEMENTATION'** heading, indicates that the following block needs implementations. Instructions details are provided for each implementation block and `To-DO` statments are also provided in the code cell. Before Starting to implement the functionality please read the instrcutions carefully and Pleaase do not modify or remove the template code!\n",
        "\n",
        "---\n",
        "### Project Description \n",
        "\n",
        "In this notebook, you will be implememnting a Convolutional Neural Network (CNN) model. You will go through different stages of data pre-processing and you will explore different methods by which we can implement a CNN model. \n",
        "\n",
        "The notebook is divided into following parts:\n",
        "\n",
        "* Section 1: Import Dataset\n",
        "* Section 2: Data Analysis & Pre-processing\n",
        "* Section 3: Data Augumentation\n",
        "* Section 4: Develop a CNN to Classify Chest X-Ray (from Scratch)\n",
        "* Section 5: Develop a CNN to Classify Chest X-Ray (using Transfer Learning)\n",
        "* Section 6: Comparison of CNN Models\n",
        "* Section 7: Testing the best CNN Model\n",
        "\n",
        "---\n",
        "## Section 1: Import Dataset\n",
        "\n",
        "### Chest X-Ray Dataset\n",
        "\n",
        "For this project, we will be using [Chest X-Ray Images Dataset](https://www.kaggle.com/datasets/paultimothymooney/chest-xray-pneumonia). This dataset consists of `5,863` X-Ray images and provides two classes of images (Normal and Pneumonia).\n",
        "\n",
        "In the cells below, first we have imported the important libraries that will be useful throughout the notebook, we also have some constant variables like `DATASET_PATH, and IMG_CLASSES`. \n",
        "\n",
        "We also have a function `load_sample_imgs` which is used to load a sample training data, by which we can visualize the sample images for each class."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Dd5QwgvIoJjU",
        "outputId": "eb6dca6a-4388-47be-a2da-3dcce722c4c4"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.chdir('/content/drive/MyDrive')"
      ],
      "metadata": {
        "id": "eEMnpUNkoQf9"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "try:\n",
        "    tpu = tf.distribute.cluster_resolver.TPUClusterResolver()\n",
        "    print('Device:', tpu.master())\n",
        "    tf.config.experimental_connect_to_cluster(tpu)\n",
        "    tf.tpu.experimental.initialize_tpu_system(tpu)\n",
        "    strategy = tf.distribute.experimental.TPUStrategy(tpu)\n",
        "except:\n",
        "    strategy = tf.distribute.get_strategy()\n",
        "print('Number of replicas:', strategy.num_replicas_in_sync)\n",
        "    \n",
        "print(tf.__version__)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L9tU4YuBnc36",
        "outputId": "da940323-24c0-4a2e-f7c0-183f316b4097"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of replicas: 1\n",
            "2.12.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-03-12T19:33:33.331123Z",
          "iopub.status.busy": "2023-03-12T19:33:33.330506Z",
          "iopub.status.idle": "2023-03-12T19:33:33.487698Z",
          "shell.execute_reply": "2023-03-12T19:33:33.486676Z",
          "shell.execute_reply.started": "2023-03-12T19:33:33.331079Z"
        },
        "id": "NTdiz_Unz79P"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Downloaded Dataset Path (in google drive)\n",
        "DATASET_PATH = \"/content/drive/MyDrive/chest_xray/\"\n",
        "IMG_CLASSES = ['NORMAL', 'PNEUMONIA']\n",
        "\n",
        "def load_sample_imgs(path):\n",
        "    imgs = []\n",
        "    for cls in IMG_CLASSES:\n",
        "        dir_path = os.path.join(path, cls)\n",
        "        img_name = os.listdir(dir_path)[0]\n",
        "        img = cv2.imread(os.path.join(dir_path, img_name))\n",
        "        cls_index = IMG_CLASSES.index(cls)\n",
        "        imgs.append([img, cls_index])\n",
        "    \n",
        "    return imgs"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "img_size = 224\n",
        "def load_data(data_dir):\n",
        "    data = [] \n",
        "    for label in IMG_CLASSES: \n",
        "        path = os.path.join(data_dir, label)\n",
        "        class_num = IMG_CLASSES.index(label)\n",
        "        for img in os.listdir(path):\n",
        "            try:\n",
        "                img_arr = cv2.imread(os.path.join(path, img), cv2.IMREAD_COLOR)\n",
        "                resized_arr = cv2.resize(img_arr, (img_size, img_size)) # Reshaping images to preferred size\n",
        "                data.append([resized_arr, class_num])\n",
        "            except Exception as e:\n",
        "                print(e)\n",
        "    return np.array(data)"
      ],
      "metadata": {
        "id": "i7cAXChloooe"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-03-12T19:34:14.068108Z",
          "iopub.status.busy": "2023-03-12T19:34:14.067154Z",
          "iopub.status.idle": "2023-03-12T19:35:43.848521Z",
          "shell.execute_reply": "2023-03-12T19:35:43.847403Z",
          "shell.execute_reply.started": "2023-03-12T19:34:14.068053Z"
        },
        "id": "AoHczjHEz79R",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "43014124-f7e4-4980-acd4-7f74daac495e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-5-83cc3de088fd>:14: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "  return np.array(data)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "There are 5216 Training Images.\n",
            "There are 16 Validation Images.\n"
          ]
        }
      ],
      "source": [
        "train_data = load_data(os.path.join(DATASET_PATH, 'train'))\n",
        "valid_data = load_data(os.path.join(DATASET_PATH, 'val'))\n",
        "\n",
        "# print number of images in each dataset\n",
        "print(f'There are {len(train_data)} Training Images.')\n",
        "print(f'There are {len(valid_data)} Validation Images.')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-03-12T19:35:43.851193Z",
          "iopub.status.busy": "2023-03-12T19:35:43.850770Z",
          "iopub.status.idle": "2023-03-12T19:35:44.181799Z",
          "shell.execute_reply": "2023-03-12T19:35:44.180661Z",
          "shell.execute_reply.started": "2023-03-12T19:35:43.851121Z"
        },
        "id": "7-svW_Prz79R",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "69b46814-8ca1-42d3-f61f-773cc79aa4b8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "There are 4185 Training Images.\n",
            "There are 1047 Validation Images.\n"
          ]
        }
      ],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "combined_data = np.concatenate((train_data, valid_data), axis=0)\n",
        "train_data, valid_data = train_test_split(combined_data, test_size=0.2, random_state=13)\n",
        "\n",
        "# print number of images in each dataset\n",
        "print(f'There are {len(train_data)} Training Images.')\n",
        "print(f'There are {len(valid_data)} Validation Images.')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QwghpLDHz79R"
      },
      "source": [
        "---\n",
        "## Section 2: Data Pre-processing\n",
        "\n",
        "Before starting to train the Deep Learning model we need to setup the dataset for best possible results. In our case as we are working with images the first thing to note is the size of all the images in the dataset and then we can move forward with all other techniques.\n",
        "\n",
        "In our case as we have already setup the constant value for the size of all the images in the dataset so we don't need to worry about the size of the images in the dataset. Now we have multiple other steps that we need to take, first we will going to split the features and labels from the dataset that we have prepared early.\n",
        "\n",
        "### Implementation\n",
        "In the function below provide the code to split the features and labels into their seperate lists and then return the numpy arrays for each one of them."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WdrbPRfJz79R"
      },
      "source": [
        "Now as the function is ready to be used, so we will going to use the function to split features and labels from the dataset. First we will going to call the function for training dataset and then for validation dataset."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TzO4tptIz79S"
      },
      "source": [
        "When using TensorFlow as backend, Keras CNNs require a 4D array (which we'll also refer to as a 4D tensor) as input, with shape\n",
        "\n",
        "$$\n",
        "(\\text{number_of_samples}, \\text{image_height}, \\text{image_width}, \\text{channels}),\n",
        "$$\n",
        "\n",
        "where `number_of_samples` corresponds to the total number of images (or samples), and `image_height`, `image_width`, and `channels` correspond to the each image height, width, and channels.\n",
        "\n",
        "By the running the cell below, we can check the tensor size of our training and validation data. First we will going to check the size of features and then we will move with labels/classes. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D7jNlnoRz79S"
      },
      "source": [
        "### IMPLEMENTATION\n",
        "For training and validation labels, we can see that we have tensors of shape `(200,)` and `(16,)`, which means we have a 1-D tensor. This is a binary dataset, which means we just have 2 classes in the dataset. For the better performance of the model we can use `One-Hot-Encoding` technique to One Hot Encode the labels, this is not a necessary step while working with Binary Classification data, but this is a cruicial step for Multi-Class Classification and that is why we also need to learn this step.\n",
        "\n",
        "In the cell below you can implement the functionality to One-Hot Encode the labels of the dataset."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_train = np.array([x[0] for x in train_data])\n",
        "y_train = np.array([x[1] for x in train_data])\n",
        "\n",
        "X_valid = np.array([x[0] for x in valid_data])\n",
        "y_valid = np.array([x[1] for x in valid_data])\n"
      ],
      "metadata": {
        "id": "ar5KoTDN6G4X"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-03-12T19:35:44.437679Z",
          "iopub.status.busy": "2023-03-12T19:35:44.437269Z",
          "iopub.status.idle": "2023-03-12T19:35:44.445044Z",
          "shell.execute_reply": "2023-03-12T19:35:44.443772Z",
          "shell.execute_reply.started": "2023-03-12T19:35:44.437639Z"
        },
        "id": "gDMa6Yxoz79S",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "21d773b7-9fdb-4e38-a890-ac4625317179"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Features Tensor Shape: (4185, 224, 224, 3)\n",
            "Validation Features Tensor Shape: (1047, 224, 224, 3)\n",
            "\n",
            "\n",
            "Training Labels Tensor Shape: (4185,)\n",
            "Validation Labels Tensor Shape: (1047,)\n"
          ]
        }
      ],
      "source": [
        "print(f'Training Features Tensor Shape: {X_train.shape}')\n",
        "print(f'Validation Features Tensor Shape: {X_valid.shape}')\n",
        "print('\\n')\n",
        "print(f'Training Labels Tensor Shape: {y_train.shape}')\n",
        "print(f'Validation Labels Tensor Shape: {y_valid.shape}')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from collections import Counter\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "# Identify the minority class\n",
        "class_counts = Counter(y_train)\n",
        "minority_class = min(class_counts, key=class_counts.get)\n",
        "\n",
        "# Separate the images of the minority class\n",
        "X_train_minority = X_train[y_train == minority_class]\n"
      ],
      "metadata": {
        "id": "94aEb6jW_L2O"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the data augmentation parameters\n",
        "data_gen_args = dict(rotation_range=10,\n",
        "                     width_shift_range=0.1,\n",
        "                     height_shift_range=0.1,\n",
        "                     zoom_range=[0.9, 1.1],\n",
        "                     horizontal_flip=True,\n",
        "                     vertical_flip=False,\n",
        "                     fill_mode='reflect',\n",
        "                     data_format='channels_last')\n",
        "\n",
        "# Create the ImageDataGenerator\n",
        "image_datagen = ImageDataGenerator(**data_gen_args)\n",
        "\n",
        "# Define the number of new samples you want to generate for the minority class\n",
        "num_new_samples = 2000\n",
        "augmented_images = []\n",
        "augmented_labels = []\n",
        "\n",
        "# Generate new samples using the ImageDataGenerator\n",
        "for _ in range(num_new_samples):\n",
        "    index = np.random.randint(0, len(X_train_minority))\n",
        "    img = X_train_minority[index]\n",
        "    img_augmented = image_datagen.random_transform(img)\n",
        "    augmented_images.append(img_augmented)\n",
        "    augmented_labels.append(minority_class)\n",
        "\n",
        "# Convert the lists to numpy arrays\n",
        "augmented_images = np.array(augmented_images)\n",
        "augmented_labels = np.array(augmented_labels)\n",
        "\n",
        "# Concatenate the original and augmented data\n",
        "X_train_balanced = np.concatenate((X_train, augmented_images), axis=0)\n",
        "y_train_balanced = np.concatenate((y_train, augmented_labels), axis=0)\n"
      ],
      "metadata": {
        "id": "i6rWokE2_UiD"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train = X_train_balanced\n",
        "y_train = y_train_balanced"
      ],
      "metadata": {
        "id": "m2exvUBC82Vm"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert labels to sequential integers\n",
        "# For correctub\n",
        "unique_labels = np.unique(y_train)\n",
        "label_map = {label: idx for idx, label in enumerate(unique_labels)}\n",
        "y_train = np.array([label_map[label] for label in y_train])\n",
        "y_valid = np.array([label_map[label] for label in y_valid])\n"
      ],
      "metadata": {
        "id": "rEoRm_8GUfvH"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-03-12T19:35:44.447627Z",
          "iopub.status.busy": "2023-03-12T19:35:44.446729Z",
          "iopub.status.idle": "2023-03-12T19:35:51.129128Z",
          "shell.execute_reply": "2023-03-12T19:35:51.128038Z",
          "shell.execute_reply.started": "2023-03-12T19:35:44.447589Z"
        },
        "id": "-FMN8aNhz79S"
      },
      "outputs": [],
      "source": [
        "from keras.utils import to_categorical\n",
        "\n",
        "# One-hot encoding for training and validation labels\n",
        "y_train = to_categorical(y_train)\n",
        "y_valid = to_categorical(y_valid)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KuvbTvJKz79S"
      },
      "source": [
        "Now after implementing the `One-Hot Encoding` functionality we can again check the shape of the labels."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-03-12T19:35:51.134405Z",
          "iopub.status.busy": "2023-03-12T19:35:51.132589Z",
          "iopub.status.idle": "2023-03-12T19:35:51.140581Z",
          "shell.execute_reply": "2023-03-12T19:35:51.139433Z",
          "shell.execute_reply.started": "2023-03-12T19:35:51.134358Z"
        },
        "id": "1UgJmfoSz79S",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "937afb1b-b2a1-4c4c-e3f0-3c260e2b4484"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Labels Tensor Shape: (6185, 2)\n",
            "Validation Labels Tensor Shape: (1047, 2)\n"
          ]
        }
      ],
      "source": [
        "print(f'Training Labels Tensor Shape: {y_train.shape}')\n",
        "print(f'Validation Labels Tensor Shape: {y_valid.shape}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TFmCLNVtz79S"
      },
      "source": [
        "Now we have setup the features and labels of the dataset, let's explore the data a bit more and let us visualize the channels of the images. We know that the data is in `3 Channels` which means that the images in the dataset are having `Reg, Blue and Green` color channel which is also known as `RGB`. By running the cell below, we can visualize the image in each color channel. "
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(f'Training Features Tensor Shape: {X_train.shape}')\n",
        "print(f'Validation Features Tensor Shape: {X_valid.shape}')\n",
        "print('\\n')\n",
        "print(f'Training Labels Tensor Shape: {y_train.shape}')\n",
        "print(f'Validation Labels Tensor Shape: {y_valid.shape}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CkyVvu5aR158",
        "outputId": "fd2970da-4af4-4ad7-9390-ab81dbd03a48"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Features Tensor Shape: (6185, 224, 224, 3)\n",
            "Validation Features Tensor Shape: (1047, 224, 224, 3)\n",
            "\n",
            "\n",
            "Training Labels Tensor Shape: (6185, 2)\n",
            "Validation Labels Tensor Shape: (1047, 2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jm-WCqPUz79T"
      },
      "source": [
        "---\n",
        "## Section 3: Data Augumentation\n",
        "\n",
        "Data augmentation is a technique used in machine learning to artificially increase the size and diversity of a dataset by generating new data from existing data. Data augmentation provides improvement in the performance of machine learning models by exposing them to a wider range of variations in the data. Data augmentation is commonly used in computer vision applications such as image classification, object detection, and segmentation. \n",
        "\n",
        "For data augumentation we can make use of multiple techniques like Flipping, Rotation, Scaling, Cropping, Translation, Adding Noise to the image, etc. \n",
        "\n",
        "### IMPLEMENTATION\n",
        "For Data Augumentation we will be using `ImageDataGenerator` function provided by `keras` library. In the cell below you have boilerplate code for the initialization of ImageDataGenerator object, while initializing the object, we need to pass in arguments which Augumentation techniques we need to use. \n",
        "\n",
        "**In the code below, we already have two arguments (Augumentation Techniques), you need to provide at least 2 more arguments to Augument the data, you can provide more as you want.** "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-03-12T19:35:51.934680Z",
          "iopub.status.busy": "2023-03-12T19:35:51.933050Z",
          "iopub.status.idle": "2023-03-12T19:35:51.950019Z",
          "shell.execute_reply": "2023-03-12T19:35:51.948906Z",
          "shell.execute_reply.started": "2023-03-12T19:35:51.934637Z"
        },
        "id": "MhR-avWmz79T"
      },
      "outputs": [],
      "source": [
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "# TODO: Provide at least 2 more data augumentation parameters,\n",
        "# we need to apply at least 4 different augumentation techniques.\n",
        "datagen = ImageDataGenerator(rescale=1./255, rotation_range=10, width_shift_range=0.1, height_shift_range=0.1 ,brightness_range=(0.8,1), zoom_range=0.2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8IyiSlXBz79T"
      },
      "source": [
        "Now after initializing the data augumentation object, we need to use this object to visualize the dataset. \n",
        "\n",
        "In the cell below, we will use one single sample image and generate the augumented images. The generator object will augument the sample image and generate different samples of the images by the help of the techniques which we have provided. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0J1I3vLXz79T"
      },
      "source": [
        "---\n",
        "## Section 4: Develop a CNN to Classify Chest X-Ray (from Scratch)\n",
        "\n",
        "We have completed the Data pre-processing part, now it is the time to start developing the Convolutional Neural Network model. For this project we will be going to work with keras and Tensorflow library to develop and train the CNN model. CNN models have multiple layers that we can use, some of the standard layers that we need to use while working with CNN models are `Convolutinal Layer, Pooling Layer, Dropout Layer, Flatten Layer and Dense Layer`.\n",
        "\n",
        "### IMPLEMENTATION\n",
        "Now in the cell below we will going to define our model architecture. You have been given a boiler plate code with 1 Convolutional Layer and Output Layer of the model. \n",
        "\n",
        "**By using the boilerplate code develop a Convolutional Model architecutre. You need to use Conv2D, Pooling, Dropout and Dense Layers, etc. Please don't change anything in the boilerplate code.**"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "img_size=224\n",
        "# deeper structure with fewer parameter\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Conv2D, MaxPooling2D, Dropout, Flatten\n",
        "\n",
        "# Building CNN model\n",
        "# Initializing the Model\n",
        "cnn_model = Sequential()\n",
        "\n",
        "# Conv Layer\n",
        "cnn_model.add(Conv2D(filters=16, kernel_size=3, padding=\"same\", activation=\"relu\", input_shape=(img_size, img_size, 3)))\n",
        "# Pooling layer\n",
        "cnn_model.add(MaxPooling2D(pool_size=2))\n",
        "# Dropout layer\n",
        "cnn_model.add(Dropout(0.25))\n",
        "\n",
        "cnn_model.add(Conv2D(filters=32, kernel_size=3, padding=\"same\", activation=\"relu\"))\n",
        "cnn_model.add(MaxPooling2D(pool_size=2))\n",
        "cnn_model.add(Dropout(0.25))\n",
        "\n",
        "cnn_model.add(Conv2D(filters=64, kernel_size=3, padding=\"same\", activation=\"relu\"))\n",
        "cnn_model.add(MaxPooling2D(pool_size=2))\n",
        "cnn_model.add(Dropout(0.25))\n",
        "\n",
        "cnn_model.add(Conv2D(filters=128, kernel_size=3, padding=\"same\", activation=\"relu\"))\n",
        "cnn_model.add(MaxPooling2D(pool_size=2))\n",
        "cnn_model.add(Dropout(0.25))\n",
        "\n",
        "cnn_model.add(Conv2D(filters=256, kernel_size=3, padding=\"same\", activation=\"relu\"))\n",
        "cnn_model.add(MaxPooling2D(pool_size=2))\n",
        "cnn_model.add(Dropout(0.25))\n",
        "\n",
        "\n",
        "# Flatten layer\n",
        "cnn_model.add(Flatten())\n",
        "\n",
        "# Dense layers\n",
        "cnn_model.add(Dense(128, activation=\"relu\"))\n",
        "cnn_model.add(Dropout(0.5))\n",
        "cnn_model.add(Dense(64, activation=\"relu\"))\n",
        "cnn_model.add(Dropout(0.5))\n",
        "\n",
        "# Output Layer of the Model\n",
        "cnn_model.add(Dense(2, activation=\"softmax\"))\n",
        "\n",
        "# Model Summary\n",
        "cnn_model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OF8wQ7W4lEw7",
        "outputId": "6a7bb250-c46b-48f2-bcb5-56ec3f1b3fff"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d (Conv2D)             (None, 224, 224, 16)      448       \n",
            "                                                                 \n",
            " max_pooling2d (MaxPooling2D  (None, 112, 112, 16)     0         \n",
            " )                                                               \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 112, 112, 16)      0         \n",
            "                                                                 \n",
            " conv2d_1 (Conv2D)           (None, 112, 112, 32)      4640      \n",
            "                                                                 \n",
            " max_pooling2d_1 (MaxPooling  (None, 56, 56, 32)       0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " dropout_1 (Dropout)         (None, 56, 56, 32)        0         \n",
            "                                                                 \n",
            " conv2d_2 (Conv2D)           (None, 56, 56, 64)        18496     \n",
            "                                                                 \n",
            " max_pooling2d_2 (MaxPooling  (None, 28, 28, 64)       0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " dropout_2 (Dropout)         (None, 28, 28, 64)        0         \n",
            "                                                                 \n",
            " conv2d_3 (Conv2D)           (None, 28, 28, 128)       73856     \n",
            "                                                                 \n",
            " max_pooling2d_3 (MaxPooling  (None, 14, 14, 128)      0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " dropout_3 (Dropout)         (None, 14, 14, 128)       0         \n",
            "                                                                 \n",
            " conv2d_4 (Conv2D)           (None, 14, 14, 256)       295168    \n",
            "                                                                 \n",
            " max_pooling2d_4 (MaxPooling  (None, 7, 7, 256)        0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " dropout_4 (Dropout)         (None, 7, 7, 256)         0         \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 12544)             0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 128)               1605760   \n",
            "                                                                 \n",
            " dropout_5 (Dropout)         (None, 128)               0         \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 64)                8256      \n",
            "                                                                 \n",
            " dropout_6 (Dropout)         (None, 64)                0         \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 2)                 130       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 2,006,754\n",
            "Trainable params: 2,006,754\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "kPaaElKSaJOW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "img_size=224\n",
        "# deeper structure with fewer parameter\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Conv2D, MaxPooling2D, Dropout, Flatten\n",
        "\n",
        "# Building CNN model\n",
        "# Initializing the Model\n",
        "cnn_model = Sequential()\n",
        "\n",
        "# Conv Layer\n",
        "cnn_model.add(Conv2D(filters=16, kernel_size=3, padding=\"same\", activation=\"relu\", input_shape=(img_size, img_size, 3)))\n",
        "# Pooling layer\n",
        "cnn_model.add(MaxPooling2D(pool_size=2))\n",
        "# Dropout layer\n",
        "cnn_model.add(Dropout(0.1))\n",
        "\n",
        "cnn_model.add(Conv2D(filters=32, kernel_size=3, padding=\"same\", activation=\"relu\"))\n",
        "cnn_model.add(MaxPooling2D(pool_size=2))\n",
        "cnn_model.add(Dropout(0.2))\n",
        "\n",
        "cnn_model.add(Conv2D(filters=64, kernel_size=3, padding=\"same\", activation=\"relu\"))\n",
        "cnn_model.add(MaxPooling2D(pool_size=2))\n",
        "cnn_model.add(Dropout(0.2))\n",
        "\n",
        "cnn_model.add(Conv2D(filters=128, kernel_size=3, padding=\"same\", activation=\"relu\"))\n",
        "cnn_model.add(MaxPooling2D(pool_size=2))\n",
        "cnn_model.add(Dropout(0.2))\n",
        "\n",
        "cnn_model.add(Conv2D(filters=256, kernel_size=3, padding=\"same\", activation=\"relu\"))\n",
        "cnn_model.add(MaxPooling2D(pool_size=2))\n",
        "cnn_model.add(Dropout(0.2))\n",
        "\n",
        "cnn_model.add(Conv2D(filters=512, kernel_size=3, padding=\"same\", activation=\"relu\"))\n",
        "cnn_model.add(MaxPooling2D(pool_size=2))\n",
        "cnn_model.add(Dropout(0.2))\n",
        "\n",
        "\n",
        "# Flatten layer\n",
        "cnn_model.add(Flatten())\n",
        "\n",
        "# Dense layers\n",
        "cnn_model.add(Dense(128, activation=\"relu\"))\n",
        "cnn_model.add(Dropout(0.5))\n",
        "cnn_model.add(Dense(64, activation=\"relu\"))\n",
        "cnn_model.add(Dropout(0.5))\n",
        "\n",
        "# Output Layer of the Model\n",
        "cnn_model.add(Dense(2, activation=\"softmax\"))\n",
        "\n",
        "# Model Summary\n",
        "cnn_model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ut1yj766aGxg",
        "outputId": "cde781cf-a28e-40a2-84f6-e49a29f6cfb0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_5 (Conv2D)           (None, 224, 224, 16)      448       \n",
            "                                                                 \n",
            " max_pooling2d_5 (MaxPooling  (None, 112, 112, 16)     0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " dropout_7 (Dropout)         (None, 112, 112, 16)      0         \n",
            "                                                                 \n",
            " conv2d_6 (Conv2D)           (None, 112, 112, 32)      4640      \n",
            "                                                                 \n",
            " max_pooling2d_6 (MaxPooling  (None, 56, 56, 32)       0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " dropout_8 (Dropout)         (None, 56, 56, 32)        0         \n",
            "                                                                 \n",
            " conv2d_7 (Conv2D)           (None, 56, 56, 64)        18496     \n",
            "                                                                 \n",
            " max_pooling2d_7 (MaxPooling  (None, 28, 28, 64)       0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " dropout_9 (Dropout)         (None, 28, 28, 64)        0         \n",
            "                                                                 \n",
            " conv2d_8 (Conv2D)           (None, 28, 28, 128)       73856     \n",
            "                                                                 \n",
            " max_pooling2d_8 (MaxPooling  (None, 14, 14, 128)      0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " dropout_10 (Dropout)        (None, 14, 14, 128)       0         \n",
            "                                                                 \n",
            " conv2d_9 (Conv2D)           (None, 14, 14, 256)       295168    \n",
            "                                                                 \n",
            " max_pooling2d_9 (MaxPooling  (None, 7, 7, 256)        0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " dropout_11 (Dropout)        (None, 7, 7, 256)         0         \n",
            "                                                                 \n",
            " conv2d_10 (Conv2D)          (None, 7, 7, 512)         1180160   \n",
            "                                                                 \n",
            " max_pooling2d_10 (MaxPoolin  (None, 3, 3, 512)        0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " dropout_12 (Dropout)        (None, 3, 3, 512)         0         \n",
            "                                                                 \n",
            " flatten_1 (Flatten)         (None, 4608)              0         \n",
            "                                                                 \n",
            " dense_3 (Dense)             (None, 128)               589952    \n",
            "                                                                 \n",
            " dropout_13 (Dropout)        (None, 128)               0         \n",
            "                                                                 \n",
            " dense_4 (Dense)             (None, 64)                8256      \n",
            "                                                                 \n",
            " dropout_14 (Dropout)        (None, 64)                0         \n",
            "                                                                 \n",
            " dense_5 (Dense)             (None, 2)                 130       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 2,171,106\n",
            "Trainable params: 2,171,106\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ikN1WvBoz79U"
      },
      "source": [
        "The output of the above cell shows the summary of the CNN model. With the help of the model summary, we can see the trainable parameters, the complexity of the model, we can also check the output data shape for each layer. This is a good way to check the complexity of the model. \n",
        "\n",
        "Now we need to compile the model. While compiling the model we need to provide `loss function`, `optimizer`, and `metrics` which will be used during the training process of the Deep Learning model. There are many different choices of loss functions and optimizers which are avilable and we need to choose the best for our use case. \n",
        "\n",
        "### IMPLEMENTATION\n",
        "In the cell below, **you need to provide the LOSS function and Optimization Function for the CNN Model**.\n",
        "\n",
        "- [Available Loss Functions](https://keras.io/api/losses/probabilistic_losses/)\n",
        "- [Available Optimization Functions](https://keras.io/api/optimizers/)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# when optimizer is \"adam\", best model Training Accuracy: 77.873 % loss 24.537975311279297\n",
        "# improve it by SGD"
      ],
      "metadata": {
        "id": "juveTzdSjelk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.optimizers import SGD\n",
        "from keras.callbacks import ReduceLROnPlateau\n",
        "sgd_optimizer = SGD(learning_rate=0.01, momentum=0.9, decay=5e-4)"
      ],
      "metadata": {
        "id": "3Y3FRjg7jwd8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "adam = tf.keras.optimizers.Adam(learning_rate=0.001, beta_1=0.9, beta_2=0.999, epsilon=1e-07)\n"
      ],
      "metadata": {
        "id": "e6liro9Ra2Z-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cnn_model.compile(loss=\"binary_crossentropy\", optimizer=sgd_optimizer, metrics=[\"accuracy\"])"
      ],
      "metadata": {
        "id": "8A4b6rl1j2p8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 169
        },
        "outputId": "2ad5d39f-0eb2-4055-a3db-a376fc6de973"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-20-02cd75b9c37c>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mcnn_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"binary_crossentropy\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msgd_optimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"accuracy\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'cnn_model' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F6XzuxQ5z79U"
      },
      "source": [
        "### IMPLEMENTATION\n",
        "\n",
        "Now in the cell below we will be going to train our Convolutional Neural Network Model. For the training of the CNN model, **you need to provide a `Batch size` and `Number of Epochs`**. And after that you can run this cell to start the training process of the model."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#!pip install --upgrade tensorflow keras"
      ],
      "metadata": {
        "id": "pZNmrkyIV2gF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.callbacks import ModelCheckpoint\n",
        "checkpoint = ModelCheckpoint(\"best_model_epoch_{epoch:02d}.h5\", monitor=\"val_accuracy\", save_best_only=True, mode=\"max\", verbose=1, save_freq='epoch')"
      ],
      "metadata": {
        "id": "bPb73BqF_Fg7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Epochs = 20 \n",
        "BATCH_SIZE = 20\n",
        "\n",
        "cnn_model_history = cnn_model.fit(X_train, y_train, batch_size=BATCH_SIZE,\n",
        "                                  validation_data=(X_valid, y_valid), epochs=Epochs,\n",
        "                                  verbose=1, shuffle=True, callbacks=[checkpoint])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 523
        },
        "id": "qpMhR7YJohx7",
        "outputId": "d1011da7-4a72-437e-c655-d11b810a9b70"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "310/310 [==============================] - ETA: 0s - loss: nan - accuracy: 0.4944\n",
            "Epoch 1: val_accuracy improved from -inf to 0.27698, saving model to best_model_epoch_01.h5\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-29-8f65c0c72daf>\u001b[0m in \u001b[0;36m<cell line: 4>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mBATCH_SIZE\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m20\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m cnn_model_history = cnn_model.fit(X_train, y_train, batch_size=BATCH_SIZE,\n\u001b[0m\u001b[1;32m      5\u001b[0m                                   \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_valid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_valid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mEpochs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m                                   verbose=1, shuffle=True, callbacks=[checkpoint])\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m         \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 65\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     66\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m             \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1745\u001b[0m                     \u001b[0mepoch_logs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_logs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1746\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1747\u001b[0;31m                 \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_epoch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch_logs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1748\u001b[0m                 \u001b[0mtraining_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mepoch_logs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstop_training\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/callbacks.py\u001b[0m in \u001b[0;36mon_epoch_end\u001b[0;34m(self, epoch, logs)\u001b[0m\n\u001b[1;32m    451\u001b[0m         \u001b[0mlogs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_process_logs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    452\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mcallback\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 453\u001b[0;31m             \u001b[0mcallback\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_epoch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    454\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    455\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/callbacks.py\u001b[0m in \u001b[0;36mon_epoch_end\u001b[0;34m(self, epoch, logs)\u001b[0m\n\u001b[1;32m   1473\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1474\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave_freq\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"epoch\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1475\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_save_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1476\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1477\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_should_save_on_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/callbacks.py\u001b[0m in \u001b[0;36m_save_model\u001b[0;34m(self, epoch, batch, logs)\u001b[0m\n\u001b[1;32m   1543\u001b[0m                                 )\n\u001b[1;32m   1544\u001b[0m                             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1545\u001b[0;31m                                 self.model.save(\n\u001b[0m\u001b[1;32m   1546\u001b[0m                                     \u001b[0mfilepath\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1547\u001b[0m                                     \u001b[0moverwrite\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m         \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 65\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     66\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m             \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36msave\u001b[0;34m(self, filepath, overwrite, save_format, **kwargs)\u001b[0m\n\u001b[1;32m   2824\u001b[0m         \u001b[0mNote\u001b[0m \u001b[0mthat\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;31m`\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0man\u001b[0m \u001b[0malias\u001b[0m \u001b[0;32mfor\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2825\u001b[0m         \"\"\"\n\u001b[0;32m-> 2826\u001b[0;31m         saving_api.save_model(\n\u001b[0m\u001b[1;32m   2827\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2828\u001b[0m             \u001b[0mfilepath\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/saving/saving_api.py\u001b[0m in \u001b[0;36msave_model\u001b[0;34m(model, filepath, overwrite, save_format, **kwargs)\u001b[0m\n\u001b[1;32m    143\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    144\u001b[0m         \u001b[0;31m# Legacy case\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 145\u001b[0;31m         return legacy_sm_saving_lib.save_model(\n\u001b[0m\u001b[1;32m    146\u001b[0m             \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    147\u001b[0m             \u001b[0mfilepath\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m         \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 65\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     66\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m             \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/saving/legacy/save.py\u001b[0m in \u001b[0;36msave_model\u001b[0;34m(model, filepath, overwrite, include_optimizer, save_format, signatures, options, save_traces)\u001b[0m\n\u001b[1;32m    158\u001b[0m                 \u001b[0;34m'setting save_format=\"tf\") or using `save_weights`.'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    159\u001b[0m             )\n\u001b[0;32m--> 160\u001b[0;31m         hdf5_format.save_model_to_hdf5(\n\u001b[0m\u001b[1;32m    161\u001b[0m             \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilepath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moverwrite\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minclude_optimizer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    162\u001b[0m         )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/saving/legacy/hdf5_format.py\u001b[0m in \u001b[0;36msave_model_to_hdf5\u001b[0;34m(model, filepath, overwrite, include_optimizer)\u001b[0m\n\u001b[1;32m    105\u001b[0m             \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgfile\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmakedirs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdirpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    106\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 107\u001b[0;31m         \u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mh5py\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"w\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    108\u001b[0m         \u001b[0mopened_new_file\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    109\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/h5py/_hl/files.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, name, mode, driver, libver, userblock_size, swmr, rdcc_nslots, rdcc_nbytes, rdcc_w0, track_order, fs_strategy, fs_persist, fs_threshold, fs_page_size, page_buf_size, min_meta_keep, min_raw_keep, locking, alignment_threshold, alignment_interval, meta_block_size, **kwds)\u001b[0m\n\u001b[1;32m    565\u001b[0m                                  \u001b[0mfs_persist\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfs_persist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfs_threshold\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfs_threshold\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    566\u001b[0m                                  fs_page_size=fs_page_size)\n\u001b[0;32m--> 567\u001b[0;31m                 \u001b[0mfid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmake_fid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muserblock_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfapl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfcpl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mswmr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mswmr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    568\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    569\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlibver\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/h5py/_hl/files.py\u001b[0m in \u001b[0;36mmake_fid\u001b[0;34m(name, mode, userblock_size, fapl, fcpl, swmr)\u001b[0m\n\u001b[1;32m    235\u001b[0m         \u001b[0mfid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mh5f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh5f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mACC_EXCL\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfapl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfapl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfcpl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfcpl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    236\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mmode\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'w'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 237\u001b[0;31m         \u001b[0mfid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mh5f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh5f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mACC_TRUNC\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfapl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfapl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfcpl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfcpl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    238\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mmode\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'a'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    239\u001b[0m         \u001b[0;31m# Open in append mode (read/write).\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32mh5py/_objects.pyx\u001b[0m in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mh5py/_objects.pyx\u001b[0m in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mh5py/h5f.pyx\u001b[0m in \u001b[0;36mh5py.h5f.create\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mh5py/h5g.pyx\u001b[0m in \u001b[0;36mh5py.h5g.GroupID.__init__\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mh5py/h5g.pyx\u001b[0m in \u001b[0;36mh5py.h5g.GroupID.__init__\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/importlib/_bootstrap.py\u001b[0m in \u001b[0;36mparent\u001b[0;34m(self)\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y4EW4pK-z79U"
      },
      "source": [
        "#### Evaluating the Trained Model\n",
        "After training the Model, it is a good paractice to evaluate the model on Training Dataset to get the final Training Accuracy and Loss of the Model. By running the cell below you will be able to find out the training accuracy and loss of the CNN model. "
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# use batchnormalize achieved 74\n",
        "# use batch+sgd 25\n",
        "# best to now: 2 million parameter 87.599 %\n",
        "#Training Accuracy: 87.599 %\n",
        "#Training Loss: 9.101021766662598"
      ],
      "metadata": {
        "id": "4GbCY9qbv7kE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-03-12T19:58:29.794926Z",
          "iopub.status.busy": "2023-03-12T19:58:29.794470Z",
          "iopub.status.idle": "2023-03-12T19:58:32.581567Z",
          "shell.execute_reply": "2023-03-12T19:58:32.580428Z",
          "shell.execute_reply.started": "2023-03-12T19:58:29.794893Z"
        },
        "id": "Yzi3pklfz79U"
      },
      "outputs": [],
      "source": [
        "cnn_model.load_weights(\"best_model_epoch_01.h5\")\n",
        "\n",
        "training_score = cnn_model.evaluate(X_train, y_train)\n",
        "\n",
        "print(\"\\nTraining Accuracy:\", round((training_score[1] * 100), 3),\"%\")\n",
        "print(\"Training Loss:\", training_score[0])"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "import numpy as np\n",
        "y_pred_probs = cnn_model.predict(X_train)\n",
        "y_pred_labels = np.argmax(y_pred_probs, axis=1)\n",
        "y_true_labels = np.argmax(y_train, axis=1)\n",
        "cm = confusion_matrix(y_true_labels, y_pred_labels)\n",
        "print(\"Confusion Matrix:\")\n",
        "print(cm)\n"
      ],
      "metadata": {
        "id": "g1J08YFCntfv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "img_size = 224\n",
        "def load_data(data_dir):\n",
        "    data = [] \n",
        "    path = data_dir\n",
        "    for img in os.listdir(path):\n",
        "            try:\n",
        "                img_arr = cv2.imread(os.path.join(path, img), cv2.IMREAD_COLOR)\n",
        "                resized_arr = cv2.resize(img_arr, (img_size, img_size)) # Reshaping images to preferred size\n",
        "                data.append([resized_arr, img])\n",
        "            except Exception as e:\n",
        "                print(e)\n",
        "    return np.array(data)\n",
        "\n",
        "test_data = load_data(os.path.join(DATASET_PATH, 'test'))\n",
        "\n",
        "# print number of images in each dataset\n",
        "print(f'There are {len(test_data)} Training Images.')\n",
        "\n",
        "X_test = np.array([x[0] for x in test_data])\n",
        "y_test = np.array([x[1] for x in test_data])\n",
        "\n",
        "print(f'Training Features Tensor Shape: {X_test.shape}')\n",
        "print(f'Training Features Tensor Shape: {y_test.shape}')\n",
        "\n",
        "y_test_prob = cnn_model.predict(X_test)\n",
        "y_test_pred = np.argmax(y_test_prob, axis=1)\n",
        "\n",
        "results_df = pd.DataFrame({\"ID\":y_test,\"class\": y_test_pred})\n",
        "df = results_df\n",
        "df['class'] = df['class'].map({0: 'NORMAL', 1: 'PNEUMONIA'})\n",
        "df['ID_number'] = df['ID'].str.extract('(\\d+)').astype(int)\n",
        "\n",
        "df_sorted = df.sort_values(by='ID_number')\n",
        "df_sorted.drop('ID_number', axis=1, inplace=True)\n",
        "\n",
        "df_sorted.to_csv(\"predicted_labels.csv\", index=False)\n",
        "\n",
        "from google.colab import files\n",
        "\n",
        "files.download(\"predicted_labels.csv\")"
      ],
      "metadata": {
        "id": "kFbNQ56TnMvD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RcCodkepz79U"
      },
      "source": [
        "---\n",
        "## Section 5: Develop a CNN to Classify Chest X-Ray (using Transfer Learning)\n",
        "\n",
        "Now in this section we will be using pre-trained CNN model and train it using Transfer Learning Techniques. Transfer learning is a powerfull technique by which we can make use of complex and large pre-trained models and improve those models on our datasets. We have many different pre-trained CNN models available, you can access the list of all pre-trainned models in Keras Document, [link to pre-trained models](https://keras.io/api/applications/). \n",
        "\n",
        "There are different types of Transfer Learning techniques available, for this project we will be using `Fine Tuning` approach. Fine-tuning in transfer learning is a technique which is used to adapt a pre-trained model to a new dataset. This involves taking a pre-trained model that has been trained on a large dataset, and then improving it for a different dataset. The idea is that the model has already learned some general features and patterns from the original dataset, and these can be useful for the new dataset.\n",
        "\n",
        "### IMPLEMENTATION\n",
        "\n",
        "The First step to implement the Fine Tuning approach is to initialize a pre-trained model. **From the list of all available pre-trained models, choose a model according to your choice and initialize it in the cell given below**."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-03-12T19:35:54.475141Z",
          "iopub.status.busy": "2023-03-12T19:35:54.474547Z",
          "iopub.status.idle": "2023-03-12T19:35:58.815564Z",
          "shell.execute_reply": "2023-03-12T19:35:58.814535Z",
          "shell.execute_reply.started": "2023-03-12T19:35:54.475103Z"
        },
        "id": "LsAwV09Bz79U"
      },
      "outputs": [],
      "source": [
        "# TODO: Initialize a pre-trained model\n",
        "import tensorflow\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras.applications import EfficientNetV2S\n",
        "\n",
        "eff_pretrained_model = EfficientNetV2S(include_top = False, weights ='imagenet',  input_shape = (224,224,3))\n",
        "\n",
        "# We don't need to train the pre-trained model we just need to fine-tune it\n",
        "\n",
        "for i, layer in enumerate(eff_pretrained_model.layers):\n",
        "    if i < len(eff_pretrained_model.layers) - 2:\n",
        "        layer.trainable = False\n",
        "    else:\n",
        "        layer.trainable = True\n",
        "# Note that setting layer.trainable = True will train model from scratch. \n",
        "# In this case, only the architechure will be the same as your pretrained models"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gv12OvDnz79U"
      },
      "source": [
        "Now in the second step of Fine Tuning, we need to add some `Dense` layers to the model. As you can see in the cell above, we have explicitly turned off the training of all the layers inside the pre-trainned model because we don't want the pre-trained model to be trained we just want to add some layers at the end of the model and then we will going to train those layers.\n",
        "\n",
        "### IMPLEMENTATION\n",
        "In the cell below, you have given a boilerplate code, the loaded pre-trained model has been attached to the CNN architecture and also the output layer of the model is initialized. **You need to add some more Dense, Dropout Layers in the CNN model architecture**."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#EFFICIENTNET\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Conv2D, MaxPooling2D, Dropout, Flatten\n",
        "eff_transfer_model = Sequential()     \n",
        "eff_transfer_model.add(eff_pretrained_model)\n",
        "eff_transfer_model.add(Flatten())\n",
        "# Hint: Add a pooling layer to reduce the input size to dense layer.\n",
        "\n",
        "#TODO: Add some Dense, Dropout Layers\n",
        "eff_transfer_model.add(Dense(128, activation='relu'))\n",
        "eff_transfer_model.add(Dropout(0.3))\n",
        "eff_transfer_model.add(Dense(16, activation='relu'))\n",
        "eff_transfer_model.add(Dropout(0.3))\n",
        "# Hint: Keep your size of Dense layer small (i.e. number of units in the dense layers. You may find colab crashing if you have too many params.)\n",
        "# Output Layer of the Model\n",
        "eff_transfer_model.add(Dense(2, activation='softmax'))\n",
        "eff_transfer_model.summary()"
      ],
      "metadata": {
        "id": "Pz8HeS-m0B2v",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ca527de8-6eef-4627-c55e-13a51d96626b"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " efficientnetv2-s (Functiona  (None, 7, 7, 1280)       20331360  \n",
            " l)                                                              \n",
            "                                                                 \n",
            " flatten_2 (Flatten)         (None, 62720)             0         \n",
            "                                                                 \n",
            " dense_7 (Dense)             (None, 128)               8028288   \n",
            "                                                                 \n",
            " dropout_5 (Dropout)         (None, 128)               0         \n",
            "                                                                 \n",
            " dense_8 (Dense)             (None, 16)                2064      \n",
            "                                                                 \n",
            " dropout_6 (Dropout)         (None, 16)                0         \n",
            "                                                                 \n",
            " dense_9 (Dense)             (None, 2)                 34        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 28,361,746\n",
            "Trainable params: 8,032,946\n",
            "Non-trainable params: 20,328,800\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#EFFICIENTNET\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Conv2D, MaxPooling2D, Dropout, Flatten\n",
        "from keras import layers\n",
        "eff_transfer_model = Sequential()     \n",
        "eff_transfer_model.add(eff_pretrained_model)\n",
        "eff_transfer_model.add(Flatten())\n",
        "# Hint: Add a pooling layer to reduce the input size to dense layer.\n",
        "#TODO: Add some Dense, Dropout Layers\n",
        "eff_transfer_model.add(Dense(512, activation='relu'))\n",
        "eff_transfer_model.add(Dropout(0.3))\n",
        "eff_transfer_model.add(Dense(128, activation='relu'))\n",
        "eff_transfer_model.add(Dropout(0.3))\n",
        "eff_transfer_model.add(Dense(32, activation='relu'))\n",
        "eff_transfer_model.add(Dropout(0.3))\n",
        "# Hint: Keep your size of Dense layer small (i.e. number of units in the dense layers. You may find colab crashing if you have too many params.)\n",
        "# Output Layer of the Model\n",
        "eff_transfer_model.add(Dense(2, activation='softmax'))\n",
        "eff_transfer_model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MJAaoIW-CRDF",
        "outputId": "2a35522a-f917-4e39-d4a3-84ce8fe1aab6"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " efficientnetv2-s (Functiona  (None, 7, 7, 1280)       20331360  \n",
            " l)                                                              \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 62720)             0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 512)               32113152  \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 512)               0         \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 128)               65664     \n",
            "                                                                 \n",
            " dropout_1 (Dropout)         (None, 128)               0         \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 32)                4128      \n",
            "                                                                 \n",
            " dropout_2 (Dropout)         (None, 32)                0         \n",
            "                                                                 \n",
            " dense_3 (Dense)             (None, 2)                 66        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 52,514,370\n",
            "Trainable params: 32,183,010\n",
            "Non-trainable params: 20,331,360\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-03-12T19:36:54.334230Z",
          "iopub.status.busy": "2023-03-12T19:36:54.333277Z",
          "iopub.status.idle": "2023-03-12T19:36:54.349966Z",
          "shell.execute_reply": "2023-03-12T19:36:54.348751Z",
          "shell.execute_reply.started": "2023-03-12T19:36:54.334172Z"
        },
        "id": "n02YLRG1z79V"
      },
      "outputs": [],
      "source": [
        "#TODO: Provide Loss and Optimizer functions\n",
        "#!!!!!!!!!!!!!\n",
        "import numpy as np\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.applications import densenet\n",
        "from keras.models import Model\n",
        "from keras.layers import Dense, GlobalAveragePooling2D\n",
        "from keras.optimizers import Adam\n",
        "eff_transfer_model.compile(optimizer=Adam(), loss='binary_crossentropy', metrics=['accuracy'])\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wedvh5wtz79V"
      },
      "source": [
        "### IMPLEMENTATION\n",
        "\n",
        "Now in the cell below we will be going to train the Convolutional Neural Network Model. As we have trained the CNN model previously, it will going to be the same steps. **Provide the code for training the CNN Model, and train the model on same number of Epochs as the previous CNN model**."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.callbacks import ModelCheckpoint\n",
        "checkpoint = ModelCheckpoint(\"best_model_epoch_{epoch:02d}.h5\", monitor=\"val_accuracy\", save_best_only=True, mode=\"max\", verbose=1, save_freq='epoch')"
      ],
      "metadata": {
        "id": "z1Ybc2bKKSy7"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "# TODO: Provide at least 2 more data augumentation parameters,\n",
        "# we need to apply at least 4 different augumentation techniques.\n",
        "datagen = ImageDataGenerator(rescale=1./255, rotation_range=10, zoom_range=0.05)"
      ],
      "metadata": {
        "id": "XdgUWNqAbcuu"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#TODO: You need to provide the Batch Size, Number of Epochs will be the same as before\n",
        "BATCH_SIZE = 32\n",
        "\n",
        "eff_transfer_model_history = eff_transfer_model.fit(datagen.flow(X_train, y_train, batch_size=BATCH_SIZE),\\\n",
        "                                            validation_data=(X_valid, y_valid), epochs=10,\\\n",
        "                                            verbose=1, shuffle=True, callbacks=[checkpoint])"
      ],
      "metadata": {
        "id": "1F5zaJbK9f6s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#TODO: You need to provide the Batch Size, Number of Epochs will be the same as before\n",
        "BATCH_SIZE = 20\n",
        "\n",
        "eff_transfer_model_history = eff_transfer_model.fit(X_train, y_train, batch_size=BATCH_SIZE,\\\n",
        "                                            validation_data=(X_valid, y_valid), epochs=10,\\\n",
        "                                            verbose=1, shuffle=True, callbacks=[checkpoint])"
      ],
      "metadata": {
        "id": "eet9mz_I5Pza",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1020dcf0-7359-48d4-9902-294e166de81d"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "309/310 [============================>.] - ETA: 0s - loss: 0.3019 - accuracy: 0.8916\n",
            "Epoch 1: val_accuracy improved from -inf to 0.88539, saving model to best_model_epoch_01.h5\n",
            "310/310 [==============================] - 71s 177ms/step - loss: 0.3019 - accuracy: 0.8915 - val_loss: 0.1743 - val_accuracy: 0.8854\n",
            "Epoch 2/10\n",
            "309/310 [============================>.] - ETA: 0s - loss: 0.1760 - accuracy: 0.9371\n",
            "Epoch 2: val_accuracy improved from 0.88539 to 0.91213, saving model to best_model_epoch_02.h5\n",
            "310/310 [==============================] - 52s 169ms/step - loss: 0.1758 - accuracy: 0.9371 - val_loss: 0.1272 - val_accuracy: 0.9121\n",
            "Epoch 3/10\n",
            "309/310 [============================>.] - ETA: 0s - loss: 0.1232 - accuracy: 0.9566\n",
            "Epoch 3: val_accuracy improved from 0.91213 to 0.93505, saving model to best_model_epoch_03.h5\n",
            "310/310 [==============================] - 50s 163ms/step - loss: 0.1231 - accuracy: 0.9567 - val_loss: 0.1030 - val_accuracy: 0.9351\n",
            "Epoch 4/10\n",
            "309/310 [============================>.] - ETA: 0s - loss: 0.0896 - accuracy: 0.9670\n",
            "Epoch 4: val_accuracy improved from 0.93505 to 0.97612, saving model to best_model_epoch_04.h5\n",
            "310/310 [==============================] - 51s 164ms/step - loss: 0.0896 - accuracy: 0.9670 - val_loss: 0.0712 - val_accuracy: 0.9761\n",
            "Epoch 5/10\n",
            "309/310 [============================>.] - ETA: 0s - loss: 0.0698 - accuracy: 0.9780\n",
            "Epoch 5: val_accuracy did not improve from 0.97612\n",
            "310/310 [==============================] - 32s 102ms/step - loss: 0.0697 - accuracy: 0.9780 - val_loss: 0.0694 - val_accuracy: 0.9761\n",
            "Epoch 6/10\n",
            "309/310 [============================>.] - ETA: 0s - loss: 0.0778 - accuracy: 0.9770\n",
            "Epoch 6: val_accuracy did not improve from 0.97612\n",
            "310/310 [==============================] - 32s 102ms/step - loss: 0.0777 - accuracy: 0.9770 - val_loss: 0.0760 - val_accuracy: 0.9675\n",
            "Epoch 7/10\n",
            "309/310 [============================>.] - ETA: 0s - loss: 0.0529 - accuracy: 0.9848\n",
            "Epoch 7: val_accuracy did not improve from 0.97612\n",
            "310/310 [==============================] - 30s 98ms/step - loss: 0.0528 - accuracy: 0.9848 - val_loss: 0.0693 - val_accuracy: 0.9752\n",
            "Epoch 8/10\n",
            "309/310 [============================>.] - ETA: 0s - loss: 0.0493 - accuracy: 0.9850\n",
            "Epoch 8: val_accuracy did not improve from 0.97612\n",
            "310/310 [==============================] - 30s 98ms/step - loss: 0.0493 - accuracy: 0.9850 - val_loss: 0.0843 - val_accuracy: 0.9675\n",
            "Epoch 9/10\n",
            "309/310 [============================>.] - ETA: 0s - loss: 0.0475 - accuracy: 0.9837\n",
            "Epoch 9: val_accuracy improved from 0.97612 to 0.98090, saving model to best_model_epoch_09.h5\n",
            "310/310 [==============================] - 44s 141ms/step - loss: 0.0475 - accuracy: 0.9837 - val_loss: 0.0737 - val_accuracy: 0.9809\n",
            "Epoch 10/10\n",
            "309/310 [============================>.] - ETA: 0s - loss: 0.0496 - accuracy: 0.9845\n",
            "Epoch 10: val_accuracy did not improve from 0.98090\n",
            "310/310 [==============================] - 32s 102ms/step - loss: 0.0496 - accuracy: 0.9845 - val_loss: 0.0686 - val_accuracy: 0.9742\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "eff_transfer_model.load_weights(\"best_model_epoch_09.h5\")\n",
        "training_score = eff_transfer_model.evaluate(X_train, y_train)\n",
        "print(\"\\nTraining Accuracy:\", round((training_score[1] * 100), 3), \"%\")\n",
        "print(\"Training Loss:\", training_score[0])"
      ],
      "metadata": {
        "id": "z0_cZ-ppG5Z6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c965afcc-f8c5-459e-bdb0-d3a3a3b92763"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "194/194 [==============================] - 23s 118ms/step - loss: 0.0060 - accuracy: 0.9984\n",
            "\n",
            "Training Accuracy: 99.838 %\n",
            "Training Loss: 0.005994182080030441\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "training_score = eff_transfer_model.evaluate(X_valid, y_valid)\n",
        "print(\"\\nTraining Accuracy:\", round((training_score[1] * 100), 3), \"%\")\n",
        "print(\"Training Loss:\", training_score[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "86WoIKyxI2mj",
        "outputId": "8a121c58-3b6d-43e9-8f82-321bb1ed2ce4"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "33/33 [==============================] - 4s 119ms/step - loss: 0.0737 - accuracy: 0.9809\n",
            "\n",
            "Training Accuracy: 98.09 %\n",
            "Training Loss: 0.0736745148897171\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "import numpy as np\n",
        "y_pred_probs = eff_transfer_model.predict(X_train)\n",
        "y_pred_labels = np.argmax(y_pred_probs, axis=1)\n",
        "y_true_labels = np.argmax(y_train, axis=1)\n",
        "cm = confusion_matrix(y_true_labels, y_pred_labels)\n",
        "print(\"Confusion Matrix:\")\n",
        "print(cm)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OcRlrQ9pI-7a",
        "outputId": "0589ecdd-bf22-41fc-8176-0cd6c309ba8b"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "194/194 [==============================] - 25s 112ms/step\n",
            "Confusion Matrix:\n",
            "[[3065    1]\n",
            " [   9 3110]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "img_size = 224\n",
        "def load_data(data_dir):\n",
        "    data = [] \n",
        "    path = data_dir\n",
        "    for img in os.listdir(path):\n",
        "            try:\n",
        "                img_arr = cv2.imread(os.path.join(path, img), cv2.IMREAD_COLOR)\n",
        "                resized_arr = cv2.resize(img_arr, (img_size, img_size)) # Reshaping images to preferred size\n",
        "                data.append([resized_arr, img])\n",
        "            except Exception as e:\n",
        "                print(e)\n",
        "    return np.array(data)\n",
        "\n",
        "test_data = load_data(os.path.join(DATASET_PATH, 'test'))\n",
        "\n",
        "# print number of images in each dataset\n",
        "print(f'There are {len(test_data)} Training Images.')\n",
        "\n",
        "X_test = np.array([x[0] for x in test_data])\n",
        "y_test = np.array([x[1] for x in test_data])\n",
        "\n",
        "print(f'Training Features Tensor Shape: {X_test.shape}')\n",
        "print(f'Training Features Tensor Shape: {y_test.shape}')\n",
        "\n",
        "y_test_prob = eff_transfer_model.predict(X_test)\n",
        "y_test_pred = np.argmax(y_test_prob, axis=1)\n",
        "\n",
        "results_df = pd.DataFrame({\"ID\":y_test,\"class\": y_test_pred})\n",
        "df = results_df\n",
        "df['class'] = df['class'].map({0: 'NORMAL', 1: 'PNEUMONIA'})\n",
        "\n",
        "df['ID_number'] = df['ID'].str.extract('(\\d+)').astype(int)\n",
        "\n",
        "df_sorted = df.sort_values(by='ID_number')\n",
        "df_sorted.drop('ID_number', axis=1, inplace=True)\n",
        "\n",
        "df_sorted.to_csv(\"predicted_labels.csv\", index=False)\n",
        "\n",
        "from google.colab import files\n",
        "\n",
        "files.download(\"predicted_labels.csv\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 141
        },
        "id": "4B-jhk5gJaN1",
        "outputId": "41c3c003-cd37-4bf6-928f-16d0062fa4a7"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-44-dd2f3f6ef981>:12: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "  return np.array(data)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "There are 624 Training Images.\n",
            "Training Features Tensor Shape: (624, 224, 224, 3)\n",
            "Training Features Tensor Shape: (624,)\n",
            "20/20 [==============================] - 2s 111ms/step\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_b20cf26c-281a-4370-8cd9-4d27d2bca065\", \"predicted_labels.csv\", 13297)"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Create a pandas DataFrame with the predicted labels\n",
        "results_df = pd.DataFrame({\"ID\":y_test,\"Label\": y_test_pred})\n",
        "\n",
        "# Save the DataFrame to a CSV file\n",
        "results_df.to_csv(\"predicted_labels.csv\", index=False)\n",
        "\n",
        "from google.colab import files\n",
        "\n",
        "files.download(\"predicted_labels.csv\")\n",
        "\n"
      ],
      "metadata": {
        "id": "OYJbBTiLJk60"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = results_df\n",
        "df"
      ],
      "metadata": {
        "id": "Bji4kXe0KdRi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['Label'] = df['Label'].map({0: 'NORMAL', 1: 'PNEUMONIA'})"
      ],
      "metadata": {
        "id": "mNMEXLCuKb87"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df"
      ],
      "metadata": {
        "id": "80jEzln0KkV9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Extract the integer part from the 'ID' column\n",
        "df['ID_number'] = df['ID'].str.extract('(\\d+)').astype(int)\n",
        "\n",
        "# Sort the dataframe based on the extracted number\n",
        "df_sorted = df.sort_values(by='ID_number')\n",
        "\n",
        "# Drop the temporary 'ID_number' column\n",
        "df_sorted.drop('ID_number', axis=1, inplace=True)"
      ],
      "metadata": {
        "id": "VRtF8eGIKp57"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_sorted"
      ],
      "metadata": {
        "id": "54hP91faKsAV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Save the DataFrame to a CSV file\n",
        "df_sorted.to_csv(\"predicted_labels.csv\", index=False)\n",
        "\n",
        "from google.colab import files\n",
        "\n",
        "files.download(\"predicted_labels.csv\")"
      ],
      "metadata": {
        "id": "xMA_CSsBLbZ3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CcE9MWcJz79V"
      },
      "source": [
        "#### Evaluating the Trained Model\n",
        "After training the Model, it is a good paractice to evaluate the model on Training Dataset to get the final Training Accuracy and Loss of the Model. By running the cell below you will be able to find out the training accuracy and loss of the CNN model which is trained by transfer learning. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-03-12T19:47:17.523482Z",
          "iopub.status.busy": "2023-03-12T19:47:17.522833Z",
          "iopub.status.idle": "2023-03-12T19:47:23.903313Z",
          "shell.execute_reply": "2023-03-12T19:47:23.901886Z",
          "shell.execute_reply.started": "2023-03-12T19:47:17.523432Z"
        },
        "id": "nhc32hQ1z79V"
      },
      "outputs": [],
      "source": [
        "res_transfer_model.load_weights(\"best_model.h5\")\n",
        "transfer_model_score = res_transfer_model.evaluate(X_train, y_train)\n",
        "\n",
        "print(\"\\nResNetTraining Accuracy:\", round((transfer_model_score[1] * 100), 3),\"%\")\n",
        "print(\"ResNet Training Loss:\", transfer_model_score[0])\n",
        "\n",
        "\n",
        "inc_transfer_model.load_weights(\"best_model.h5\")\n",
        "transfer_model_score = inc_transfer_model.evaluate(X_train, y_train)\n",
        "\n",
        "print(\"\\nInception Training Accuracy:\", round((transfer_model_score[1] * 100), 3),\"%\")\n",
        "print(\"Inception Training Loss:\", transfer_model_score[0])\n",
        "\n",
        "\n",
        "den_transfer_model.load_weights(\"best_model.h5\")\n",
        "transfer_model_score = den_transfer_model.evaluate(X_train, y_train)\n",
        "\n",
        "print(\"\\nDenseNet Training Accuracy:\", round((transfer_model_score[1] * 100), 3),\"%\")\n",
        "print(\"DenseNet Training Loss:\", transfer_model_score[0])\n",
        "\n",
        "\n",
        "\n",
        "transfer_model_score = eff_transfer_model.evaluate(X_train, y_train)\n",
        "\n",
        "print(\"\\nEfficientNet Training Accuracy:\", round((transfer_model_score[1] * 100), 3),\"%\")\n",
        "print(\"EfficientNet Training Loss:\", transfer_model_score[0])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9LUPfsasz79V"
      },
      "source": [
        "---\n",
        "## Section 6: Comparison of CNN Models\n",
        "\n",
        "### Visualizing Model Loss And Accuracy\n",
        "\n",
        "We have successfully trained both CNN models and now it's time to compare the accuracy and loss of both models to know which one is the best one. While training the models, we can see that we have used **cnn_model_history variable** and **transfer_model_history variable**, these variable are used to store the accuracy and loss of the model for all Epochs. These variable holds the data in the form of python dictionary.\n",
        "\n",
        "### IMPLEMENTATION\n",
        "**By using the `cnn_model_history` and `transfer_model_history` variables and matplotlib library plot the Accuracy and Loss graphs of the models. You need to plot Accuracy and Loss graphs having Training and Validation data for both models.**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-03-12T20:00:32.890573Z",
          "iopub.status.busy": "2023-03-12T20:00:32.889444Z",
          "iopub.status.idle": "2023-03-12T20:00:33.183055Z",
          "shell.execute_reply": "2023-03-12T20:00:33.182012Z",
          "shell.execute_reply.started": "2023-03-12T20:00:32.890527Z"
        },
        "id": "C9Th_gBAz79V"
      },
      "outputs": [],
      "source": [
        "#TODO: Plot the Accuracy Graph"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-03-12T20:01:36.168718Z",
          "iopub.status.busy": "2023-03-12T20:01:36.168296Z",
          "iopub.status.idle": "2023-03-12T20:01:36.436584Z",
          "shell.execute_reply": "2023-03-12T20:01:36.435389Z",
          "shell.execute_reply.started": "2023-03-12T20:01:36.168666Z"
        },
        "id": "Oz19ZBmIz79V"
      },
      "outputs": [],
      "source": [
        "#TODO: Plot the Loss Graph"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BoUmQgffz79V"
      },
      "source": [
        "---\n",
        "## Section 7: Testing the best CNN Model\n",
        "\n",
        "Now in this last section of the Notebook, we will test the best CNN model.\n",
        "\n",
        "#### IMPLEMENTATION\n",
        "**Load the testing set in the cell below.**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-03-12T20:03:13.268522Z",
          "iopub.status.busy": "2023-03-12T20:03:13.268117Z",
          "iopub.status.idle": "2023-03-12T20:03:22.958488Z",
          "shell.execute_reply": "2023-03-12T20:03:22.957392Z",
          "shell.execute_reply.started": "2023-03-12T20:03:13.268486Z"
        },
        "id": "dGNesuEbz79W"
      },
      "outputs": [],
      "source": [
        "# TODO: Load the Testing Dataset\n",
        "test_data = None\n",
        "\n",
        "# print number of images in testing dataset\n",
        "print(f'There are {len(test_data)} Testing Images.')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7hufQ9ZAz79W"
      },
      "source": [
        "### IMPLEMENTATION\n",
        "**Split the Features and Labels of the Testing Set.**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-03-12T20:03:22.960885Z",
          "iopub.status.busy": "2023-03-12T20:03:22.960391Z",
          "iopub.status.idle": "2023-03-12T20:03:23.001588Z",
          "shell.execute_reply": "2023-03-12T20:03:23.000223Z",
          "shell.execute_reply.started": "2023-03-12T20:03:22.960835Z"
        },
        "id": "cZodIEyFz79W"
      },
      "outputs": [],
      "source": [
        "# TODO: Split the Features and Labels of Testing Data\n",
        "x_test, y_test = None\n",
        "\n",
        "print(f'Testing Features Tensor Shape: {x_test.shape}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Uxnoym3Hz79W"
      },
      "source": [
        "We have loaded and setup the testing dataset, now it's time to use the best model and make the prediction for testing images."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-03-12T20:03:31.130390Z",
          "iopub.status.busy": "2023-03-12T20:03:31.129664Z",
          "iopub.status.idle": "2023-03-12T20:03:32.998447Z",
          "shell.execute_reply": "2023-03-12T20:03:32.997322Z",
          "shell.execute_reply.started": "2023-03-12T20:03:31.130351Z"
        },
        "id": "Zmy7jG5yz79W"
      },
      "outputs": [],
      "source": [
        "predictions = transfer_model.predict(x_test)\n",
        "prediction_labels = np.argmax(predictions, axis=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YHUI-1YIz79W"
      },
      "source": [
        "### Confusion Matrix\n",
        "A confusion matrix is a table used to evaluate the performance of a classification model. It shows the number of correct and incorrect predictions made by the model compared to the actual outcomes. The matrix is usually presented as a square table, with the rows representing the actual class labels and the columns representing the predicted class labels. The confusion matrix provides several useful metrics for evaluating the performance of a classification model, such as accuracy, precision, recall, and F1 score. \n",
        "\n",
        "### IMPLEMENTATION\n",
        "We have original labels and predicted labels, now you need to use **scikit-learn** and **matplotlib** lilbrary to plot the confusion matrix."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-03-12T20:03:36.736614Z",
          "iopub.status.busy": "2023-03-12T20:03:36.735574Z",
          "iopub.status.idle": "2023-03-12T20:03:37.346568Z",
          "shell.execute_reply": "2023-03-12T20:03:37.344378Z",
          "shell.execute_reply.started": "2023-03-12T20:03:36.736575Z"
        },
        "id": "bGv14SRTz79W"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import ConfusionMatrixDisplay, classification_report\n",
        "\n",
        "#TODO: Compute and Plot the Confusion matrix for testing data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tTlBUYxGz79W"
      },
      "source": [
        "### Classification Report\n",
        "\n",
        "A classification report is a summary of the key performance metrics for a classification model. The classification report includes several important metrics, including precision, recall, F1 score, and support. These metrics provide information about the model's ability to correctly identify positive and negative instances, as well as the balance between precision and recall.\n",
        "\n",
        "Please run the cell below to generate the classification report for the Best Performing CNN Model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-03-12T20:03:41.459189Z",
          "iopub.status.busy": "2023-03-12T20:03:41.458154Z",
          "iopub.status.idle": "2023-03-12T20:03:41.471691Z",
          "shell.execute_reply": "2023-03-12T20:03:41.470448Z",
          "shell.execute_reply.started": "2023-03-12T20:03:41.459137Z"
        },
        "id": "vAc2KcBJz79W"
      },
      "outputs": [],
      "source": [
        "print(classification_report(y_test, prediction_labels))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wLXvp6agz79W"
      },
      "source": [
        "---\n",
        "## Conclusion\n",
        "\n",
        "In the Notebook, we have learned how we can develop Convolutional Neural Network Models. We have learned how we can develop our own CNN architectures and how we can make use of Transfer Learning Techniques. We have gone through the data preperation part, model development part and finally we have evaluated and tested the CNN Models. "
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.14"
    },
    "colab": {
      "provenance": [],
      "gpuType": "A100",
      "machine_shape": "hm"
    },
    "gpuClass": "standard",
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}